{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77568d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import openpyxl\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee59cc",
   "metadata": {},
   "source": [
    "#### 定义输入输出路径，并加载数据\n",
    "- `dataset_dirs`：三个医学数据集表格路径\n",
    "- `statistics_output_dir`：统计数据表输出路径，包括属性值、选择率、基数\n",
    "- `valid_where_output_dir`：所有有效谓词组合的输出路径\n",
    "- **注意**：支持 .csv 格式，自动处理编码问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集路径配置\n",
    "dataset_dirs = {\n",
    "    \"disease\": r\"/data2/liujinqi/Benchmark/Query/Medical_Autoconstruct/disease.csv\",\n",
    "    \"drug\": r\"/data2/liujinqi/Benchmark/Query/Medical_Autoconstruct/drug.csv\", \n",
    "    \"institutes\": r\"/data2/liujinqi/Benchmark/Query/Medical_Autoconstruct/institutes.csv\"\n",
    "}\n",
    "\n",
    "statistics_output_dir = r\"/data2/liujinqi/Benchmark/Query/Medical_Autoconstruct/medical_statistics.csv\"\n",
    "valid_where_output_dir = r\"/data2/liujinqi/Benchmark/Query/Medical_Autoconstruct/valid_WHERE.json\"\n",
    "\n",
    "# 表之间的关系定义\n",
    "table_relationships = [\n",
    "    (\"disease\", \"drug\", \"disease_name\", \"disease_name\"),\n",
    "    (\"drug\", \"institutes\", \"manufacturer\", \"institution_name\"),\n",
    "    (\"disease\", \"institutes\", \"disease_name\", \"research_diseases\")  # 多值匹配\n",
    "]\n",
    "\n",
    "# 加载数据函数\n",
    "def load_tables():\n",
    "    tables = {}\n",
    "    for table_name, file_path in dataset_dirs.items():\n",
    "        try:\n",
    "            tables[table_name] = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except:\n",
    "            tables[table_name] = pd.read_csv(file_path, encoding='cp1252')\n",
    "        print(f\"Loaded {table_name}: {len(tables[table_name])} rows\")\n",
    "    return tables\n",
    "\n",
    "# 加载数据\n",
    "tables = load_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31896c1",
   "metadata": {},
   "source": [
    "\n",
    "#### 定义属性，方便后面按不同属性类型设计不同的构造方法\n",
    "- `attr_desc_dict`：全部属性的集合，以及对应的自然语言描述\n",
    "- `disease_attributes`、`drug_attributes`、`institute_attributes`：各表特有属性\n",
    "- `non_numerical_attr`：非数值属性的集合\n",
    "- `numerical_attr`：数值属性的集合（establishment_year, number_of_staff）\n",
    "- `category_attr`：固定类别的属性\n",
    "- `multi_value_attributes`：多值的属性，用\"||\"分隔或者逗号分隔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_desc_dict = {\n",
    "    # Disease表属性\n",
    "    \"disease_name\": \"\", \"disease_type\": \"\", \"pathogenesis\": \"\", \"etiology\": \"\",\n",
    "    \"diagnostic_methods\": \"\", \"common_symptoms\": \"\", \"complications\": \"\", \"affected_organs\": \"\",\n",
    "    \"treatments\": \"\", \"drugs\": \"\", \"prognosis\": \"\", \"sequelae\": \"\", \"epidemiology\": \"\",\n",
    "    \"risk_factors\": \"\", \"preventive_measures\": \"\", \"diagnosis_challenges\": \"\",\n",
    "    \"treatment_challenges\": \"\", \"quality_of_life_impact\": \"\",\n",
    "    \n",
    "    # Drug表属性\n",
    "    \"generic_name\": \"\", \"brand_name\": \"\", \"indication\": \"\", \"active_ingredients\": \"\",\n",
    "    \"pharmaceutical_form\": \"\", \"manufacturer\": \"\", \"administration_route\": \"\",\n",
    "    \"recommended_usage\": \"\", \"single_dose\": \"\", \"dosage_frequency\": \"\",\n",
    "    \"mechanism_of_action\": \"\", \"side_effects\": \"\", \"activation_conditions\": \"\",\n",
    "    \"prescription_status\": \"\", \"unsuitable_population\": \"\", \"storage_conditions\": \"\",\n",
    "    \n",
    "    # Institute表属性\n",
    "    \"institution_name\": \"\", \"institution_type\": \"\", \"parent_organization\": \"\", \"leadership\": \"\",\n",
    "    \"institution_country\": \"\", \"institution_city\": \"\", \"research_diseases\": \"\",\n",
    "    \"research_fields\": \"\", \"key_technologies\": \"\", \"key_achievements\": \"\",\n",
    "    \"international_collaboration\": \"\", \"funding_sources\": \"\", \"technology_application\": \"\",\n",
    "    \"ID\": \"\"\n",
    "}\n",
    "\n",
    "disease_attributes = [\n",
    "    \"disease_name\", \"disease_type\", \"pathogenesis\", \"etiology\", \"diagnostic_methods\",\n",
    "    \"common_symptoms\", \"complications\", \"affected_organs\", \"treatments\", \"drugs\",\n",
    "    \"prognosis\", \"sequelae\", \"epidemiology\", \"risk_factors\", \"preventive_measures\",\n",
    "    \"diagnosis_challenges\", \"treatment_challenges\", \"quality_of_life_impact\",\n",
    "]\n",
    "\n",
    "drug_attributes = [\n",
    "    \"generic_name\", \"brand_name\", \"disease_name\", \"indication\", \"active_ingredients\",\n",
    "    \"pharmaceutical_form\", \"manufacturer\", \"administration_route\", \"recommended_usage\",\n",
    "    \"single_dose\", \"dosage_frequency\", \"mechanism_of_action\", \"side_effects\",\n",
    "    \"activation_conditions\", \"prescription_status\", \"unsuitable_population\",\n",
    "    \"storage_conditions\",\n",
    "]\n",
    "\n",
    "institute_attributes = [\n",
    "    \"institution_name\", \"institution_type\", \"parent_organization\", \"leadership\", \"institution_country\", \"institution_city\",\n",
    "    \"research_diseases\", \"research_fields\", \"key_technologies\", \"key_achievements\",\n",
    "    \"international_collaboration\", \"funding_sources\", \"technology_application\", \n",
    "]\n",
    "\n",
    "table_attributes = {\n",
    "    \"disease\": {attr: attr_desc_dict[attr] for attr in disease_attributes},\n",
    "    \"drug\": {attr: attr_desc_dict[attr] for attr in drug_attributes},\n",
    "    \"institutes\": {attr: attr_desc_dict[attr] for attr in institute_attributes}\n",
    "}\n",
    "\n",
    "non_numerical_attr_list = [\n",
    "    \"disease_name\", \"disease_type\", \"pathogenesis\", \"etiology\", \"diagnostic_methods\",\n",
    "    \"common_symptoms\", \"complications\", \"affected_organs\", \"treatments\", \"drugs\",\n",
    "    \"prognosis\", \"sequelae\", \"epidemiology\", \"risk_factors\", \"preventive_measures\", \n",
    "    \"diagnosis_challenges\", \"treatment_challenges\", \"quality_of_life_impact\",\n",
    "    \"generic_name\", \"brand_name\", \"disease_name\", \"indication\", \"active_ingredients\",\n",
    "    \"pharmaceutical_form\", \"manufacturer\", \"administration_route\", \"recommended_usage\",\n",
    "    \"single_dose\", \"dosage_frequency\", \"mechanism_of_action\", \"side_effects\",\n",
    "    \"activation_conditions\", \"prescription_status\", \"unsuitable_population\", \n",
    "    \"storage_conditions\", \"institution_name\", \"institution_type\", \"parent_organization\", \n",
    "    \"leadership\", \"institution_country\", \"institution_city\", \"research_diseases\", \n",
    "    \"research_fields\", \"key_technologies\", \"key_achievements\", \"international_collaboration\",\n",
    "    \"funding_sources\", \"technology_application\",\n",
    "]\n",
    "\n",
    "numerical_attr_list = []\n",
    "\n",
    "multi_value_attributes_list = [\n",
    "    \"disease_name\", \"disease_type\", \"pathogenesis\", \"etiology\", \"indication\", \"diagnostic_methods\", \n",
    "    \"common_symptoms\", \"active_ingredients\", \"generic_name\", \"brand_name\", \"pharmaceutical_form\",\n",
    "    \"manufacturer\", \"administration_route\", \"recommended_usage\", \"single_dose\", \"dosage_frequency\", \n",
    "    \"mechanism_of_action\", \"side_effects\", \"activation_conditions\", \"prescription_status\", \n",
    "    \"unsuitable_population\", \"storage_conditions\",\n",
    "    \n",
    "    \"institution_name\", \"institution_type\", \"parent_organization\",  \n",
    "    \"leadership\", \"institution_country\", \"institution_city\", \"research_diseases\",\n",
    "    \"research_fields\", \"key_technologies\", \"key_achievements\", \"international_collaboration\", \n",
    "    \"funding_sources\", \"technology_application\",\n",
    "\n",
    "    \"generic_name\", \"brand_name\", \"disease_name\", \"indication\", \"active_ingredients\", \"pharmaceutical_form\",\n",
    "    \"manufacturer\", \"administration_route\", \"recommended_usage\", \"single_dose\", \"dosage_frequency\", \n",
    "    \"mechanism_of_action\", \"side_effects\", \"activation_conditions\", \"prescription_status\", \"unsuitable_population\",\n",
    "    \"storage_conditions\"\n",
    "]\n",
    "\n",
    "category_attr_list = [\n",
    "    \"disease_type\",\"pathogenesis\",\"diagnostic_methods\",\"treatments\",\"prognosis\",\n",
    "    \"risk_factors\",\"preventive_measures\",\"quality_of_life_impact\",\"institution_type\",\"pharmaceutical_form\",\n",
    "    \"administration_route\",\"recommended_usage\",\"activation_conditions\",\"prescription_status\",\"storage_conditions\"\n",
    "]\n",
    "\n",
    "# 按表分组\n",
    "non_numerical_attr = {\n",
    "    \"disease\": [attr for attr in disease_attributes if attr in non_numerical_attr_list],\n",
    "    \"drug\": [attr for attr in drug_attributes if attr in non_numerical_attr_list],\n",
    "    \"institutes\": [attr for attr in institute_attributes if attr in non_numerical_attr_list]\n",
    "}\n",
    "\n",
    "numerical_attr = {\n",
    "    \"disease\": [attr for attr in disease_attributes if attr in numerical_attr_list],\n",
    "    \"drug\": [attr for attr in drug_attributes if attr in numerical_attr_list],\n",
    "    \"institutes\": [attr for attr in institute_attributes if attr in numerical_attr_list]\n",
    "}\n",
    "\n",
    "multi_value_attributes = {\n",
    "    \"disease\": [attr for attr in disease_attributes if attr in multi_value_attributes_list],\n",
    "    \"drug\": [attr for attr in drug_attributes if attr in multi_value_attributes_list],\n",
    "    \"institutes\": [attr for attr in institute_attributes if attr in multi_value_attributes_list]\n",
    "}\n",
    "\n",
    "category_attr = {\n",
    "    \"disease\": [attr for attr in disease_attributes if attr in category_attr_list],\n",
    "    \"drug\": [attr for attr in drug_attributes if attr in category_attr_list],\n",
    "    \"institutes\": [attr for attr in institute_attributes if attr in category_attr_list]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d154890",
   "metadata": {},
   "source": [
    "#### 生成统计信息\n",
    "- 属性 | 属性值 | 选择率 | 基数\n",
    "- 用于后续构造 Filter\n",
    "- 输出CSV格式，类似于原始Wikiart统计表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b109567",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_medical_statistics(tables):\n",
    "    combined_statistics = pd.DataFrame()\n",
    "    \n",
    "    for table_name, df in tqdm(tables.items(), desc=\"生成统计信息\"):\n",
    "        for column in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性\", leave=False):\n",
    "            if column not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # 检查是否为多值属性\n",
    "            if column in multi_value_attributes_list:\n",
    "                # 处理多值属性：只统计拆分后的单个值\n",
    "                all_values = []\n",
    "                total_rows = len(df)\n",
    "                \n",
    "                for cell in df[column].dropna():\n",
    "                    cell_str = str(cell)\n",
    "                    if '||' in cell_str:\n",
    "                        # 拆分||分隔的值\n",
    "                        split_values = [v.strip() for v in cell_str.split('||') if v.strip()]\n",
    "                        all_values.extend(split_values)\n",
    "                    elif ',' in cell_str:\n",
    "                        # 拆分逗号分隔的值\n",
    "                        split_values = [v.strip() for v in cell_str.split(',') if v.strip()]\n",
    "                        all_values.extend(split_values)\n",
    "                    else:\n",
    "                        all_values.append(cell_str.strip())\n",
    "                \n",
    "                # 统计拆分后的单个值\n",
    "                value_counts = pd.Series(all_values).value_counts()\n",
    "                # 计算selectivity：每个值出现的次数 / 总行数\n",
    "                selectivities = (value_counts / total_rows).round(3)\n",
    "            else:\n",
    "                # 普通属性的处理\n",
    "                value_counts = df[column].value_counts()\n",
    "                selectivities = df[column].value_counts(normalize=True).round(3)\n",
    "            \n",
    "            null_count = df[column].isnull().sum()\n",
    "            \n",
    "            column_stats = pd.DataFrame({\n",
    "                f\"{table_name}.{column}\": list(value_counts.index) + [\"(null)\"],\n",
    "                'Count': list(value_counts.values) + [null_count],\n",
    "                'Selectivity': list(selectivities.values) + [round(null_count / len(df), 3)]\n",
    "            })\n",
    "            \n",
    "            if combined_statistics.empty:\n",
    "                combined_statistics = column_stats\n",
    "            else:\n",
    "                combined_statistics = pd.concat([combined_statistics, column_stats], axis=1)\n",
    "    \n",
    "    return combined_statistics\n",
    "\n",
    "medical_statistics = generate_medical_statistics(tables)\n",
    "medical_statistics.to_csv(statistics_output_dir, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc308b",
   "metadata": {},
   "source": [
    "#### 定义查询构造参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb15597",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_filters = 5\n",
    "min_rows = 5\n",
    "max_select = 4\n",
    "limit_list = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "# 各类查询数量\n",
    "sample_sf = 20         # SELECT FROM (单表)\n",
    "sample_sfj = 30        # SELECT FROM JOIN\n",
    "sample_sfw = 30        # SELECT FROM WHERE (单表)\n",
    "sample_sfwj = 50       # SELECT FROM WHERE JOIN\n",
    "sample_sfwt = 20       # SELECT FROM WHERE TOP-K (单表)\n",
    "sample_sfwtj = 30      # SELECT FROM WHERE TOP-K JOIN\n",
    "sample_sfwg = 20       # SELECT FROM WHERE GROUP BY (单表)\n",
    "sample_sfwgj = 30      # SELECT FROM WHERE GROUP BY JOIN\n",
    "sample_sfwa = 20       # SELECT FROM WHERE AGGREGATION (单表)\n",
    "sample_sfwaj = 30      # SELECT FROM WHERE AGGREGATION JOIN\n",
    "sample_sfag = 20       # SELECT FROM AGGREGATION GROUP BY (单表)\n",
    "sample_sfagj = 30      # SELECT FROM AGGREGATION GROUP BY JOIN\n",
    "sample_sfwga = 30      # SELECT FROM WHERE GROUP BY AGGREGATION (单表)\n",
    "sample_sfwgaj = 40     # SELECT FROM WHERE GROUP BY AGGREGATION JOIN\n",
    "sample_sfwgat = 20     # SELECT FROM WHERE GROUP BY AGGREGATION TOP-K (单表)\n",
    "sample_sfwgatj = 30    # SELECT FROM WHERE GROUP BY AGGREGATION TOP-K JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72926439",
   "metadata": {},
   "source": [
    "#### 定义Filter执行方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_numerical_equal_to(value, condition):\n",
    "    try:\n",
    "        return str(value).lower().strip() == str(condition).lower().strip()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def non_numerical_equal_to_with_split(cell, condition):\n",
    "    if pd.isna(cell):\n",
    "        return False\n",
    "    cell_str = str(cell)\n",
    "    if '||' in cell_str:\n",
    "        return condition in cell_str.split('||')\n",
    "    elif ',' in cell_str:\n",
    "        return condition in [v.strip() for v in cell_str.split(',')]\n",
    "    return non_numerical_equal_to(cell, condition)\n",
    "\n",
    "def number_greater_than(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) > float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_less_than(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) < float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_equal_to(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) == float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_greater_equal(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) >= float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_less_equal(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) <= float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def non_numerical_equal_to_with_split(cell, condition):\n",
    "    if pd.isna(cell):\n",
    "        return False\n",
    "    cell_str = str(cell)\n",
    "    if '||' in cell_str:\n",
    "        # 修正：添加strip()处理，确保正确匹配\n",
    "        return condition in [v.strip() for v in cell_str.split('||')]\n",
    "    elif ',' in cell_str:\n",
    "        return condition in [v.strip() for v in cell_str.split(',')]\n",
    "    return non_numerical_equal_to(cell, condition)\n",
    "\n",
    "def validate_join_relationships(tables):\n",
    "    \"\"\"验证表之间是否存在有效的JOIN关系\"\"\"\n",
    "    valid_pairs = {\n",
    "        (\"disease\", \"drug\"): \"disease_name\",\n",
    "        (\"drug\", \"institutes\"): \"manufacturer -> institution_name\", \n",
    "        (\"disease\", \"institutes\"): \"disease_name in research_diseases\"\n",
    "    }\n",
    "    \n",
    "    if len(tables) <= 1:\n",
    "        return True, \"Single table, no JOIN needed\"\n",
    "    \n",
    "    for i in range(len(tables)):\n",
    "        for j in range(i+1, len(tables)):\n",
    "            table1, table2 = sorted([tables[i], tables[j]])\n",
    "            pair = (table1, table2)\n",
    "            \n",
    "            if pair not in valid_pairs:\n",
    "                return False, f\"No valid JOIN relationship between {table1} and {table2}\"\n",
    "    \n",
    "    return True, \"All JOIN relationships are valid\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d265cec",
   "metadata": {},
   "source": [
    "#### 汇总可取属性值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ee2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_values(tables):\n",
    "    attr_value_dict = {}\n",
    "    \n",
    "    for table_name, df in tqdm(tables.items(), desc=\"获取属性值\"):\n",
    "        attr_value_dict[table_name] = {}\n",
    "        for attr in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性值\", leave=False):\n",
    "            if attr in df.columns:\n",
    "                non_null_values = df[attr].dropna()\n",
    "                \n",
    "                if attr in numerical_attr_list:\n",
    "                    try:\n",
    "                        numeric_values = pd.to_numeric(non_null_values, errors='coerce').dropna()\n",
    "                        if len(numeric_values) > 0:\n",
    "                            quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "                            sample_values = [numeric_values.quantile(q) for q in quantiles]\n",
    "                            sample_values.extend(numeric_values.unique()[:10])\n",
    "                            attr_value_dict[table_name][attr] = list(set(sample_values))[:15]\n",
    "                    except:\n",
    "                        attr_value_dict[table_name][attr] = []\n",
    "                else:\n",
    "                    # 检查是否为多值属性\n",
    "                    if attr in multi_value_attributes_list:\n",
    "                        # 处理多值属性：只提取拆分后的单个值\n",
    "                        all_values = []\n",
    "                        for cell in non_null_values:\n",
    "                            cell_str = str(cell)\n",
    "                            if '||' in cell_str:\n",
    "                                # 拆分||分隔的值\n",
    "                                split_values = [v.strip() for v in cell_str.split('||') if v.strip()]\n",
    "                                all_values.extend(split_values)\n",
    "                            elif ',' in cell_str:\n",
    "                                # 拆分逗号分隔的值\n",
    "                                split_values = [v.strip() for v in cell_str.split(',') if v.strip()]\n",
    "                                all_values.extend(split_values)\n",
    "                            else:\n",
    "                                all_values.append(cell_str.strip())\n",
    "                        \n",
    "                        # 去重并取前20个单个值\n",
    "                        unique_values = list(set(all_values))[:20]\n",
    "                        attr_value_dict[table_name][attr] = unique_values\n",
    "                    else:\n",
    "                        # 普通属性的处理\n",
    "                        unique_values = non_null_values.unique()[:20]\n",
    "                        attr_value_dict[table_name][attr] = list(unique_values)\n",
    "    \n",
    "    return attr_value_dict\n",
    "\n",
    "attr_value_dict = get_sample_values(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcbb10a",
   "metadata": {},
   "source": [
    "#### 枚举所有可能的Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbac179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filter_dict(tables, attr_value_dict):\n",
    "    filter_dict = {}\n",
    "    \n",
    "    for table_name, df in tqdm(tables.items(), desc=\"处理表\"):\n",
    "        filter_dict[table_name] = {}\n",
    "        \n",
    "        for attr in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性\", leave=False):\n",
    "            if attr not in df.columns or attr not in attr_value_dict[table_name]:\n",
    "                continue\n",
    "                \n",
    "            condition_dict = {}\n",
    "            \n",
    "            if attr in non_numerical_attr[table_name]:\n",
    "                # 确保只使用拆分后的单个值，过滤掉任何包含||的值\n",
    "                clean_values = []\n",
    "                for value in attr_value_dict[table_name][attr][:10]:\n",
    "                    value_str = str(value).strip()\n",
    "                    # 跳过包含||的值，确保只使用单个值\n",
    "                    if '||' not in value_str and value_str:\n",
    "                        clean_values.append(value_str)\n",
    "                \n",
    "                for possible_value in clean_values:\n",
    "                    if attr in multi_value_attributes.get(table_name, []):\n",
    "                        result = df[attr].apply(non_numerical_equal_to_with_split, condition=possible_value)\n",
    "                    else:\n",
    "                        result = df[attr].apply(non_numerical_equal_to, condition=possible_value)\n",
    "                    \n",
    "                    result_indices = df[result].index.tolist()\n",
    "                    if len(result_indices) >= min_rows:\n",
    "                        condition_dict[f\"=='{possible_value}'\"] = result_indices\n",
    "            \n",
    "            elif attr in numerical_attr[table_name]:\n",
    "                for possible_value in attr_value_dict[table_name][attr][:8]:\n",
    "                    try:\n",
    "                        possible_value = float(possible_value)\n",
    "                        \n",
    "                        operations = [\n",
    "                            (number_greater_than, f\">{possible_value}\"),\n",
    "                            (number_less_than, f\"<{possible_value}\"),\n",
    "                            (number_equal_to, f\"=={possible_value}\"),\n",
    "                            (number_greater_equal, f\">={possible_value}\"),\n",
    "                            (number_less_equal, f\"<={possible_value}\")\n",
    "                        ]\n",
    "                        \n",
    "                        for operation_func, operation_str in operations:\n",
    "                            result = df[attr].apply(operation_func, condition=possible_value)\n",
    "                            result_indices = df[result].index.tolist()\n",
    "                            if len(result_indices) >= min_rows:\n",
    "                                condition_dict[operation_str] = result_indices\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            filter_dict[table_name][attr] = condition_dict\n",
    "    \n",
    "    return filter_dict\n",
    "\n",
    "filter_dict = build_filter_dict(tables, attr_value_dict)\n",
    "\n",
    "with open(\"./filter_dict_multi_table.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(filter_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecaa70f",
   "metadata": {},
   "source": [
    "#### 均匀采样函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ad8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample(filters, sample_size=80, random_seed=None):\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    if len(filters) <= sample_size:\n",
    "        return filters\n",
    "    \n",
    "    table_to_filters = defaultdict(list)\n",
    "    for filter_item in filters:\n",
    "        table = filter_item[0]\n",
    "        table_to_filters[table].append(filter_item)\n",
    "    \n",
    "    tables = list(table_to_filters.keys())\n",
    "    per_table = sample_size // len(tables)\n",
    "    remainder = sample_size % len(tables)\n",
    "    \n",
    "    sampled_filters = []\n",
    "    for i, table in enumerate(tables):\n",
    "        table_filters = table_to_filters[table]\n",
    "        table_sample_size = per_table + (1 if i < remainder else 0)\n",
    "        table_sample_size = min(table_sample_size, len(table_filters))\n",
    "        \n",
    "        sampled = random.sample(table_filters, table_sample_size)\n",
    "        sampled_filters.extend(sampled)\n",
    "    \n",
    "    return sampled_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391afc40",
   "metadata": {},
   "source": [
    "#### 构建WHERE条件组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_where_combinations(filter_dict, max_combinations=1000):     \n",
    "    all_filters = []          \n",
    "    for table_name, table_filters in filter_dict.items():         \n",
    "        for attr, conditions in table_filters.items():             \n",
    "            for cond, indices in conditions.items():                 \n",
    "                if len(indices) >= min_rows:                     \n",
    "                    all_filters.append((table_name, attr, cond, set(indices)))          \n",
    "\n",
    "    # 增加采样数量，确保有足够的filter进行组合     \n",
    "    sampled_filters = balanced_sample(all_filters, sample_size=80, random_seed=42)          \n",
    "\n",
    "    valid_where = []     \n",
    "    seen_expressions = set()          \n",
    "\n",
    "    for n in tqdm(range(1, min(6, len(sampled_filters) + 1)), desc=\"生成Filter组合\"):  # 修改为最多5个filter\n",
    "        combinations = list(itertools.combinations(sampled_filters, n))         \n",
    "        random.shuffle(combinations)                  \n",
    "\n",
    "        # 按照2:3:3:1:1的比例分配不同数量的filter组合\n",
    "        if n == 1:             \n",
    "            max_combos_this_round = int(max_combinations * 2 / 10)  # 2/10\n",
    "        elif n == 2:             \n",
    "            max_combos_this_round = int(max_combinations * 3 / 10)  # 3/10\n",
    "        elif n == 3:             \n",
    "            max_combos_this_round = int(max_combinations * 3 / 10)  # 3/10\n",
    "        elif n == 4:             \n",
    "            max_combos_this_round = int(max_combinations * 1 / 10)  # 1/10\n",
    "        elif n == 5:             \n",
    "            max_combos_this_round = int(max_combinations * 1 / 10)  # 1/10\n",
    "        else:\n",
    "            max_combos_this_round = 0                      \n",
    "\n",
    "        combo_count = 0         \n",
    "        for combo in tqdm(combinations, desc=f\"{n}个Filter组合\", leave=False):             \n",
    "            if combo_count >= max_combos_this_round:                 \n",
    "                break                              \n",
    "\n",
    "            for op in ['AND', 'OR']:                 \n",
    "                if n == 1:                     \n",
    "                    where_clause = f\"{combo[0][1]}{combo[0][2]}\"                     \n",
    "                    result_indices = combo[0][3]                     \n",
    "                    tables_involved = [combo[0][0]]                 \n",
    "                else:                     \n",
    "                    predicates = [f\"{item[1]}{item[2]}\" for item in combo]                     \n",
    "                    where_clause = f\" {op} \".join(predicates)                                          \n",
    "\n",
    "                    # 改进多表和单表的逻辑处理                     \n",
    "                    combo_tables = [item[0] for item in combo]                     \n",
    "                    if len(set(combo_tables)) == 1:                         \n",
    "                        # 同一个表的多个条件                         \n",
    "                        if op == 'AND':                             \n",
    "                            result_indices = set.intersection(*[item[3] for item in combo])                         \n",
    "                        else:  # OR                             \n",
    "                            result_indices = set.union(*[item[3] for item in combo])                     \n",
    "                    else:                         \n",
    "                        # 多表条件：简化处理，取第一个条件的结果                         \n",
    "                        # 实际应该做JOIN处理，这里简化                         \n",
    "                        result_indices = combo[0][3]                                          \n",
    "                    \n",
    "                    tables_involved = list(set(combo_tables))                                  \n",
    "\n",
    "                if len(result_indices) >= min_rows and where_clause not in seen_expressions:                     \n",
    "                    seen_expressions.add(where_clause)                                          \n",
    "\n",
    "                    query_dict = {                         \n",
    "                        \"WHERE Indices\": list(result_indices),                         \n",
    "                        \"WHERE Total Rows\": len(result_indices),                         \n",
    "                        \"WHERE\": where_clause,                         \n",
    "                        \"Tables\": tables_involved,                         \n",
    "                        \"Combination\": [[item[0], item[1], item[2]] for item in combo],                         \n",
    "                        \"Operator\": op if n > 1 else \"NONE\",                         \n",
    "                        \"Filter Count\": n  # 添加filter数量标识                     \n",
    "                    }                     \n",
    "                    valid_where.append(query_dict)                          \n",
    "\n",
    "                combo_count += 1          \n",
    "\n",
    "    return valid_where  \n",
    "\n",
    "valid_where = build_where_combinations(filter_dict)  \n",
    "\n",
    "with open(valid_where_output_dir, 'w', encoding='utf-8') as f:     \n",
    "    json.dump(valid_where, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4339cb6",
   "metadata": {},
   "source": [
    "#### 定义SCHEMA创建函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(attr_desc_dict, query_attr_list):\n",
    "    schema = {}\n",
    "    for key in query_attr_list:\n",
    "        if key in non_numerical_attr_list:\n",
    "            schema[key] = [\"VARCHAR(255)\", attr_desc_dict.get(key, \"\")]\n",
    "        elif key in numerical_attr_list:\n",
    "            schema[key] = [\"FLOAT\", attr_desc_dict.get(key, \"\")]\n",
    "        else:\n",
    "            schema[key] = [\"VARCHAR(255)\", attr_desc_dict.get(key, \"\")]\n",
    "    return schema\n",
    "\n",
    "def create_multi_table_schema(tables, selected_attrs):\n",
    "    schema = {}\n",
    "    \n",
    "    for table, attr in selected_attrs:\n",
    "        column_name = f\"{table}.{attr}\"\n",
    "        \n",
    "        if attr in numerical_attr_list:\n",
    "            schema[column_name] = [\"FLOAT\", f\"{table} table {attr} field\"]\n",
    "        else:\n",
    "            schema[column_name] = [\"VARCHAR(255)\", f\"{table} table {attr} field\"]\n",
    "    \n",
    "    return schema\n",
    "\n",
    "# 通用的WHERE条件选择函数\n",
    "def select_where_by_ratio(valid_where, total_needed, single_table_only=True, multi_table_ratio=0.3):\n",
    "    \"\"\"\n",
    "    按比例选择WHERE条件\n",
    "    multi_table_ratio: 多filter的比例 (默认30%单filter, 70%多filter)\n",
    "    \"\"\"\n",
    "    if single_table_only:\n",
    "        single_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) == 1 and len(w[\"Tables\"]) == 1]\n",
    "        multi_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) > 1 and len(w[\"Tables\"]) == 1]\n",
    "    else:\n",
    "        single_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) == 1]\n",
    "        multi_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) > 1]\n",
    "    \n",
    "    single_count = int(total_needed * (1 - multi_table_ratio))\n",
    "    multi_count = total_needed - single_count\n",
    "    \n",
    "    selected = multi_filter[:multi_count] + single_filter[:single_count]\n",
    "    return selected[:total_needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045703e1",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM（单表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_select_from_queries(tables):\n",
    "    \"\"\"\n",
    "    生成简单的SELECT FROM查询（单表，无WHERE条件）\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # 为每个表生成查询\n",
    "    table_names = list(tables.keys())\n",
    "    queries_per_table = sample_sf // len(table_names)\n",
    "    remainder = sample_sf % len(table_names)\n",
    "    \n",
    "    for i, table_name in enumerate(tqdm(table_names, desc=\"生成SF查询\")):\n",
    "        table_query_count = queries_per_table + (1 if i < remainder else 0)\n",
    "        \n",
    "        for _ in range(table_query_count):\n",
    "            available_attrs = list(table_attributes[table_name].keys())\n",
    "            \n",
    "            # 随机选择属性数量（1到max_select之间）\n",
    "            num_attrs = random.randint(1, min(max_select, len(available_attrs)))\n",
    "            selected_attrs = random.sample(available_attrs, num_attrs)\n",
    "            \n",
    "            # 计算表的总行数\n",
    "            total_rows = len(tables[table_name])\n",
    "            \n",
    "            query_dict = {\n",
    "                \"Type\": \"SF\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"WHERE Indices\": list(range(total_rows)),  # 所有行的索引\n",
    "                \"WHERE Total Rows\": total_rows,  # 表的总行数\n",
    "                \"WHERE\": \"\",  # 无WHERE条件\n",
    "                \"Tables\": [table_name],\n",
    "                \"Combination\": [],  # 无filter组合\n",
    "                \"Operator\": \"NONE\",\n",
    "                \"Filter Count\": 0,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, selected_attrs)\n",
    "            }\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sf_queries = generate_select_from_queries(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf16f9a",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM JOIN查询（多表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_select_from_join_queries(tables):\n",
    "    \"\"\"\n",
    "    生成SELECT FROM JOIN查询（多表，无WHERE条件）\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # 定义可能的JOIN组合\n",
    "    join_combinations = [\n",
    "        ['disease', 'drug'], \n",
    "        ['drug', 'institutes'], \n",
    "        ['disease', 'institutes'],\n",
    "        ['disease', 'drug', 'institutes']\n",
    "    ]\n",
    "    \n",
    "    # 为每种JOIN组合生成查询\n",
    "    queries_per_combo = sample_sfj // len(join_combinations)\n",
    "    remainder = sample_sfj % len(join_combinations)\n",
    "    \n",
    "    for i, join_combo in enumerate(tqdm(join_combinations, desc=\"生成SFJ查询\")):\n",
    "        combo_query_count = queries_per_combo + (1 if i < remainder else 0)\n",
    "        \n",
    "        for _ in range(combo_query_count):\n",
    "            # 从每个表中选择属性\n",
    "            available_attrs = []\n",
    "            for table in join_combo:\n",
    "                # 每个表最多选择3个属性，避免SELECT子句过长\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:5]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "            \n",
    "            # 随机选择属性数量（2到max_select之间）\n",
    "            num_attrs = random.randint(2, min(max_select, len(available_attrs)))\n",
    "            selected_attrs = random.sample(available_attrs, num_attrs)\n",
    "            select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "            \n",
    "            # 估算JOIN结果行数：使用参与表中行数最小的表作为估算\n",
    "            estimated_rows = min(len(tables[table]) for table in join_combo)\n",
    "            \n",
    "            query_dict = {\n",
    "                \"Type\": \"SFJ\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"WHERE Indices\": [],  # JOIN查询的具体索引需要执行才能确定\n",
    "                \"WHERE Total Rows\": estimated_rows,  # 使用估算的行数\n",
    "                \"WHERE\": \"\",  # 无WHERE条件\n",
    "                \"Tables\": join_combo,\n",
    "                \"Combination\": [],  # 无filter组合\n",
    "                \"Operator\": \"NONE\", \n",
    "                \"Filter Count\": 0,\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "            }\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sfj_queries = generate_select_from_join_queries(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d766d",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE查询（单表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6843354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_select_from_where_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    selected_where = select_where_by_ratio(valid_where, sample_sfw, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in tqdm(selected_where, desc=\"生成SFW查询\"):\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        available_attrs = list(table_attributes[table_name].keys())[:8]\n",
    "        selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "        \n",
    "        query_attr_list = selected_attrs.copy()\n",
    "        for item in where_dict[\"Combination\"]:\n",
    "            if item[1] not in query_attr_list:\n",
    "                query_attr_list.append(item[1])\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFW\",\n",
    "            \"SELECT\": selected_attrs,\n",
    "            \"FROM\": [table_name],\n",
    "            \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sfw_queries = generate_select_from_where_queries(valid_where, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590732f",
   "metadata": {},
   "source": [
    "#### 构建多表JOIN查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c13cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_join_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    # 多表WHERE条件的JOIN查询\n",
    "    for where_dict in tqdm(multi_table_where, desc=\"生成多表JOIN查询\"):\n",
    "        tables_involved = where_dict[\"Tables\"] if len(where_dict[\"Tables\"]) > 1 else ['disease', 'drug']\n",
    "        \n",
    "        available_attrs = []\n",
    "        for table in tables_involved:\n",
    "            table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "            available_attrs.extend(table_attrs)\n",
    "        \n",
    "        selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "        select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFWJ\",\n",
    "            \"SELECT\": select_clause,\n",
    "            \"FROM\": tables_involved,\n",
    "            \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "            \"SCHEMA\": create_multi_table_schema(tables_involved, selected_attrs)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    # 单表WHERE条件应用到JOIN查询\n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes'], ['disease', 'drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in tqdm(single_table_for_join[:10], desc=\"生成单表->JOIN查询\", leave=False):\n",
    "        for join_combo in join_combinations[:2]:\n",
    "            available_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "            \n",
    "            selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "            select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWJ\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "join_queries = generate_join_queries(valid_where, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952db05a",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE TOP-K查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topk_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    order_options = ['ASC', 'DESC']\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwt, single_table_only=True, multi_table_ratio=0.6)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        available_attrs = list(table_attributes[table_name].keys())\n",
    "        numerical_attrs = [attr for attr in available_attrs if attr in numerical_attr_list]\n",
    "        \n",
    "        if numerical_attrs:\n",
    "            selected_attrs = random.sample(available_attrs[:8], min(max_select, len(available_attrs[:8])))\n",
    "            order_column = random.choice(numerical_attrs)\n",
    "            order_type = random.choice(order_options)\n",
    "            limit_value = random.choice(limit_list)\n",
    "            \n",
    "            query_attr_list = selected_attrs + [order_column]\n",
    "            for item in where_dict[\"Combination\"]:\n",
    "                if item[1] not in query_attr_list:\n",
    "                    query_attr_list.append(item[1])\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWT\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"ORDER BY\": [order_column, order_type],\n",
    "                \"LIMIT\": limit_value,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN TOP-K查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwtj//2, single_table_only=False, multi_table_ratio=0.7)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwtj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes'], ['disease', 'drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:10]:\n",
    "        for join_combo in join_combinations[:2]:\n",
    "            available_attrs = []\n",
    "            numerical_join_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in table_attributes[table].keys() \n",
    "                                 if attr in numerical_attr_list]\n",
    "                numerical_join_attrs.extend(table_numerical)\n",
    "            \n",
    "            if numerical_join_attrs:\n",
    "                selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "                select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "                \n",
    "                order_table, order_attr = random.choice(numerical_join_attrs)\n",
    "                order_column = f\"{order_table}.{order_attr}\"\n",
    "                order_type = random.choice(order_options)\n",
    "                limit_value = random.choice(limit_list)\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWTJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"ORDER BY\": [order_column, order_type],\n",
    "                    \"LIMIT\": limit_value,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "topk_queries = generate_topk_queries(valid_where, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155cfd1",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f473bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groupby_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwg, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            selected_attrs = random.sample(list(table_attributes[table_name].keys())[:8], \n",
    "                                         min(max_select, len(list(table_attributes[table_name].keys())[:8])))\n",
    "            \n",
    "            if groupby_columns[0] not in selected_attrs:\n",
    "                selected_attrs = groupby_columns + selected_attrs[:max_select-1]\n",
    "            \n",
    "            query_attr_list = selected_attrs.copy()\n",
    "            for item in where_dict[\"Combination\"]:\n",
    "                if item[1] not in query_attr_list:\n",
    "                    query_attr_list.append(item[1])\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWG\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN GROUP BY查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwgj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwgj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:10]:\n",
    "        for join_combo in join_combinations:\n",
    "            join_category_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                available_attrs = []\n",
    "                for table in join_combo:\n",
    "                    table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                    available_attrs.extend(table_attrs)\n",
    "                \n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                selected_attrs = random.sample(available_attrs, min(max_select-1, len(available_attrs)))\n",
    "                selected_attrs.append((groupby_table, groupby_attr))\n",
    "                select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWGJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "groupby_queries = generate_groupby_queries(valid_where, tables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb6d8a",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE AGGREGATION查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aggregation_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwa, single_table_only=True, multi_table_ratio=0.6)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if numerical_attrs:\n",
    "            agg_column = random.choice(numerical_attrs)\n",
    "            function = random.choice(aggregation_functions[1:])\n",
    "            numerical = True\n",
    "        else:\n",
    "            agg_column = \"*\"\n",
    "            function = 'COUNT'\n",
    "            numerical = False\n",
    "        \n",
    "        query_attr_list = [agg_column] if agg_column != \"*\" else []\n",
    "        for item in where_dict[\"Combination\"]:\n",
    "            if item[1] not in query_attr_list:\n",
    "                query_attr_list.append(item[1])\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFWA\",\n",
    "            \"SELECT\": [f\"{function}({agg_column})\"],\n",
    "            \"FROM\": [table_name],\n",
    "            \"AGGREGATION\": [agg_column],\n",
    "            \"AGGREGATION Function\": function,\n",
    "            \"Numerical\": numerical,\n",
    "            \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    # JOIN AGGREGATION查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwaj//2, single_table_only=False, multi_table_ratio=0.7)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwaj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:10]:\n",
    "        for join_combo in join_combinations:\n",
    "            join_numerical_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_numerical_attrs:\n",
    "                agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWAJ\",\n",
    "                \"SELECT\": [f\"{function}({agg_column})\"],\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, [(agg_table, agg_attr)] if agg_column != \"*\" else [])\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "\n",
    "aggregation_queries = generate_aggregation_queries(valid_where, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e81ca",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM AGGREGATION GROUP BY查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aggregation_groupby_queries(tables):\n",
    "    \"\"\"\n",
    "    生成SELECT FROM AGGREGATION GROUP BY查询（无WHERE条件）\n",
    "    SFAG: 单表聚合分组查询\n",
    "    SFAGJ: 多表JOIN聚合分组查询\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    \n",
    "    # 1. 单表SFAG查询\n",
    "    table_names = list(tables.keys())\n",
    "    queries_per_table = sample_sfag // len(table_names)\n",
    "    remainder = sample_sfag % len(table_names)\n",
    "    \n",
    "    for i, table_name in enumerate(tqdm(table_names, desc=\"生成SFAG查询\")):\n",
    "        table_query_count = queries_per_table + (1 if i < remainder else 0)\n",
    "        \n",
    "        for _ in range(table_query_count):\n",
    "            category_attrs = category_attr.get(table_name, [])\n",
    "            numerical_attrs = numerical_attr.get(table_name, [])\n",
    "            \n",
    "            if category_attrs:\n",
    "                # 选择分组列\n",
    "                groupby_columns = random.sample(category_attrs, 1)\n",
    "                \n",
    "                # 选择聚合列和函数\n",
    "                if numerical_attrs and random.random() > 0.5:\n",
    "                    agg_column = random.choice(numerical_attrs)\n",
    "                    function = random.choice(aggregation_functions[1:])  # 排除COUNT\n",
    "                    numerical = True\n",
    "                else:\n",
    "                    agg_column = \"*\"\n",
    "                    function = 'COUNT'\n",
    "                    numerical = False\n",
    "                \n",
    "                # 构建SELECT子句\n",
    "                select_clause = groupby_columns + [f\"{function}({agg_column})\"]\n",
    "                \n",
    "                # 计算估算行数（分组后行数通常是总行数的一小部分）\n",
    "                total_rows = len(tables[table_name])\n",
    "                estimated_rows = max(1, total_rows // 5)  # 假设分组后大约1/5的行数\n",
    "                \n",
    "                query_dict = {\n",
    "                    \"Type\": \"SFAG\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": [table_name],\n",
    "                    \"GROUP BY\": groupby_columns,\n",
    "                    \"AGGREGATION\": [agg_column],\n",
    "                    \"AGGREGATION Function\": function,\n",
    "                    \"Numerical\": numerical,\n",
    "                    \"WHERE Indices\": list(range(total_rows)),  # 无WHERE条件，包含所有行\n",
    "                    \"WHERE Total Rows\": estimated_rows,  # 分组后的估算行数\n",
    "                    \"WHERE\": \"\",  # 无WHERE条件\n",
    "                    \"Tables\": [table_name],\n",
    "                    \"Combination\": [],  # 无filter组合\n",
    "                    \"Operator\": \"NONE\",\n",
    "                    \"Filter Count\": 0,\n",
    "                    \"SCHEMA\": create_schema(attr_desc_dict, groupby_columns + ([agg_column] if agg_column != \"*\" else []))\n",
    "                }\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    # 2. 多表SFAGJ查询\n",
    "    join_combinations = [\n",
    "        ['disease', 'drug'], \n",
    "        ['drug', 'institutes'], \n",
    "        ['disease', 'institutes'],\n",
    "        ['disease', 'drug', 'institutes']\n",
    "    ]\n",
    "    \n",
    "    queries_per_combo = sample_sfagj // len(join_combinations)\n",
    "    remainder_j = sample_sfagj % len(join_combinations)\n",
    "    \n",
    "    for i, join_combo in enumerate(tqdm(join_combinations, desc=\"生成SFAGJ查询\")):\n",
    "        combo_query_count = queries_per_combo + (1 if i < remainder_j else 0)\n",
    "        \n",
    "        for _ in range(combo_query_count):\n",
    "            # 收集所有表的分类属性和数值属性\n",
    "            join_category_attrs = []\n",
    "            join_numerical_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                # 选择分组列\n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                # 选择聚合列和函数\n",
    "                if join_numerical_attrs and random.random() > 0.5:\n",
    "                    agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                    agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                    function = random.choice(aggregation_functions[1:])\n",
    "                    numerical = True\n",
    "                    selected_attrs = [(groupby_table, groupby_attr), (agg_table, agg_attr)]\n",
    "                else:\n",
    "                    agg_column = \"*\"\n",
    "                    function = 'COUNT'\n",
    "                    numerical = False\n",
    "                    selected_attrs = [(groupby_table, groupby_attr)]\n",
    "                \n",
    "                # 构建SELECT子句\n",
    "                select_clause = [groupby_column, f\"{function}({agg_column})\"]\n",
    "                \n",
    "                # 估算JOIN后的行数\n",
    "                estimated_rows = max(1, min(len(tables[table]) for table in join_combo if table in tables) // 3)\n",
    "                \n",
    "                query_dict = {\n",
    "                    \"Type\": \"SFAGJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"AGGREGATION\": [agg_column],\n",
    "                    \"AGGREGATION Function\": function,\n",
    "                    \"Numerical\": numerical,\n",
    "                    \"WHERE Indices\": [],  # JOIN查询的具体索引需要执行才能确定\n",
    "                    \"WHERE Total Rows\": estimated_rows,\n",
    "                    \"WHERE\": \"\",  # 无WHERE条件\n",
    "                    \"Tables\": join_combo,\n",
    "                    \"Combination\": [],  # 无filter组合\n",
    "                    \"Operator\": \"NONE\",\n",
    "                    \"Filter Count\": 0,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                }\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# 生成SFAG查询\n",
    "sfag_queries = generate_aggregation_groupby_queries(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970af79",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY AGGREGATION查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groupby_aggregation_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwga, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            \n",
    "            if numerical_attrs:\n",
    "                agg_column = random.choice(numerical_attrs)\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "            \n",
    "            select_clause = groupby_columns + [f\"{function}({agg_column})\"]\n",
    "            \n",
    "            query_attr_list = groupby_columns + ([agg_column] if agg_column != \"*\" else [])\n",
    "            for item in where_dict[\"Combination\"]:\n",
    "                if item[1] not in query_attr_list:\n",
    "                    query_attr_list.append(item[1])\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWGA\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN GROUP BY AGGREGATION查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwgaj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwgaj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:10]:\n",
    "        for join_combo in join_combinations:\n",
    "            join_category_attrs = []\n",
    "            join_numerical_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                if join_numerical_attrs:\n",
    "                    agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                    agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                    function = random.choice(aggregation_functions[1:])\n",
    "                    numerical = True\n",
    "                    selected_attrs = [(groupby_table, groupby_attr), (agg_table, agg_attr)]\n",
    "                else:\n",
    "                    agg_column = \"*\"\n",
    "                    function = 'COUNT'\n",
    "                    numerical = False\n",
    "                    selected_attrs = [(groupby_table, groupby_attr)]\n",
    "                \n",
    "                select_clause = [groupby_column, f\"{function}({agg_column})\"]\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWGAJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"AGGREGATION\": [agg_column],\n",
    "                    \"AGGREGATION Function\": function,\n",
    "                    \"Numerical\": numerical,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "\n",
    "groupby_aggregation_queries = generate_groupby_aggregation_queries(valid_where, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ee02c",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY AGGREGATION TOP-K查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7058ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groupby_aggregation_topk_queries(valid_where, tables):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    order_options = ['ASC', 'DESC']\n",
    "    \n",
    "    # 修改：按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwgat, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            \n",
    "            if numerical_attrs and random.random() > 0.5:\n",
    "                agg_column = random.choice(numerical_attrs)\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "                order_column = f\"{function}({agg_column})\"\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "                order_column = f\"COUNT(*)\"\n",
    "            \n",
    "            order_type = random.choice(order_options)\n",
    "            limit_value = random.choice(limit_list)\n",
    "            \n",
    "            select_clause = groupby_columns + [f\"{function}({agg_column})\"]\n",
    "            \n",
    "            query_attr_list = groupby_columns + ([agg_column] if agg_column != \"*\" else [])\n",
    "            for item in where_dict[\"Combination\"]:\n",
    "                if item[1] not in query_attr_list:\n",
    "                    query_attr_list.append(item[1])\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWGAT\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"ORDER BY\": [order_column, order_type],\n",
    "                \"LIMIT\": limit_value,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN GROUP BY AGGREGATION TOP-K查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwgatj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwgatj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['disease', 'drug'], ['drug', 'institutes']]\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:8]:\n",
    "        for join_combo in join_combinations:\n",
    "            join_category_attrs = []\n",
    "            join_numerical_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                if join_numerical_attrs and random.random() > 0.5:\n",
    "                    agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                    agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                    function = random.choice(aggregation_functions[1:])\n",
    "                    numerical = True\n",
    "                    selected_attrs = [(groupby_table, groupby_attr), (agg_table, agg_attr)]\n",
    "                    order_column = f\"{function}({agg_column})\"\n",
    "                else:\n",
    "                    agg_column = \"*\"\n",
    "                    function = 'COUNT'\n",
    "                    numerical = False\n",
    "                    selected_attrs = [(groupby_table, groupby_attr)]\n",
    "                    order_column = f\"COUNT(*)\"\n",
    "                \n",
    "                order_type = random.choice(order_options)\n",
    "                limit_value = random.choice(limit_list)\n",
    "                \n",
    "                select_clause = [groupby_column, f\"{function}({agg_column})\"]\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWGATJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"AGGREGATION\": [agg_column],\n",
    "                    \"AGGREGATION Function\": function,\n",
    "                    \"Numerical\": numerical,\n",
    "                    \"ORDER BY\": [order_column, order_type],\n",
    "                    \"LIMIT\": limit_value,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "groupby_aggregation_topk_queries = generate_groupby_aggregation_topk_queries(valid_where, tables)\n",
    "\n",
    "def generate_sql_query(query_dict):\n",
    "    tables = query_dict.get(\"FROM\", [])\n",
    "    \n",
    "    select_clause = \"SELECT \" + \", \".join(query_dict[\"SELECT\"])\n",
    "    \n",
    "    if len(tables) == 1:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "    else:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "        for i in range(1, len(tables)):\n",
    "            join_condition = None\n",
    "            for t1, t2, key1, key2 in table_relationships:\n",
    "                if (tables[i-1] == t1 and tables[i] == t2) or (tables[i-1] == t2 and tables[i] == t1):\n",
    "                    if tables[i-1] == t1:\n",
    "                        left_key, right_key = key1, key2\n",
    "                        left_table, right_table = t1, t2\n",
    "                    else:\n",
    "                        left_key, right_key = key2, key1\n",
    "                        left_table, right_table = t2, t1\n",
    "                    join_condition = f\"{left_table}.{left_key} = {right_table}.{right_key}\"\n",
    "                    break\n",
    "            \n",
    "            if join_condition:\n",
    "                from_clause += f\"\\nINNER JOIN {tables[i]} ON {join_condition}\"\n",
    "    \n",
    "    where_clause = \"\"\n",
    "    if \"WHERE\" in query_dict:\n",
    "        where_clause = f\"WHERE {query_dict['WHERE']}\"\n",
    "    \n",
    "    sql_parts = [select_clause, from_clause]\n",
    "    if where_clause:\n",
    "        sql_parts.append(where_clause)\n",
    "    \n",
    "    return \"\\n\".join(sql_parts) + \";\"\n",
    "\n",
    "def generate_schema_sql(schema_dict, table_name=\"Medical_Table\"):\n",
    "    create_table = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    columns = []\n",
    "    \n",
    "    for col_name, (data_type, description) in schema_dict.items():\n",
    "        comment = f\" COMMENT '{description}'\" if description else \"\"\n",
    "        columns.append(f\"    {col_name} {data_type}{comment}\")\n",
    "    \n",
    "    create_table += \",\\n\".join(columns)\n",
    "    create_table += \"\\n);\"\n",
    "    \n",
    "    return create_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63b8b3",
   "metadata": {},
   "source": [
    "#### SQL生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(query_dict):\n",
    "    tables = query_dict.get(\"FROM\", [])\n",
    "    \n",
    "    select_clause = \"SELECT \" + \", \".join(query_dict[\"SELECT\"])\n",
    "    \n",
    "    if len(tables) == 1:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "    else:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "        for i in range(1, len(tables)):\n",
    "            join_condition = None\n",
    "            for t1, t2, key1, key2 in table_relationships:\n",
    "                if (tables[i-1] == t1 and tables[i] == t2) or (tables[i-1] == t2 and tables[i] == t1):\n",
    "                    if tables[i-1] == t1:\n",
    "                        left_key, right_key = key1, key2\n",
    "                        left_table, right_table = t1, t2\n",
    "                    else:\n",
    "                        left_key, right_key = key2, key1\n",
    "                        left_table, right_table = t2, t1\n",
    "                    join_condition = f\"{left_table}.{left_key} = {right_table}.{right_key}\"\n",
    "                    break\n",
    "            \n",
    "            if join_condition:\n",
    "                from_clause += f\"\\nINNER JOIN {tables[i]} ON {join_condition}\"\n",
    "    \n",
    "    where_clause = \"\"\n",
    "    if \"WHERE\" in query_dict:\n",
    "        where_clause = f\"WHERE {query_dict['WHERE']}\"\n",
    "    \n",
    "    group_by_clause = \"\"\n",
    "    if \"GROUP BY\" in query_dict:\n",
    "        group_by_clause = f\"GROUP BY {', '.join(query_dict['GROUP BY'])}\"\n",
    "    \n",
    "    order_by_clause = \"\"\n",
    "    if \"ORDER BY\" in query_dict:\n",
    "        order_col, order_type = query_dict[\"ORDER BY\"]\n",
    "        order_by_clause = f\"ORDER BY {order_col} {order_type}\"\n",
    "    \n",
    "    limit_clause = \"\"\n",
    "    if \"LIMIT\" in query_dict:\n",
    "        limit_clause = f\"LIMIT {query_dict['LIMIT']}\"\n",
    "    \n",
    "    sql_parts = [select_clause, from_clause]\n",
    "    if where_clause:\n",
    "        sql_parts.append(where_clause)\n",
    "    if group_by_clause:\n",
    "        sql_parts.append(group_by_clause)\n",
    "    if order_by_clause:\n",
    "        sql_parts.append(order_by_clause)\n",
    "    if limit_clause:\n",
    "        sql_parts.append(limit_clause)\n",
    "    \n",
    "    return \"\\n\".join(sql_parts) + \";\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275d6f1",
   "metadata": {},
   "source": [
    "#### 保存所有查询结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b976bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_sql_query(query_dict):\n",
    "    \"\"\"生成SQL语句 - 修复版本\"\"\"\n",
    "    tables = query_dict.get(\"FROM\", [\"medical_table\"])\n",
    "    select_fields = query_dict.get(\"SELECT\", [\"*\"])\n",
    "    \n",
    "    select_clause = \"SELECT \" + \", \".join(select_fields)\n",
    "    \n",
    "    if len(tables) == 1:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "    else:\n",
    "        from_clause = f\"FROM {tables[0]}\"\n",
    "        \n",
    "        # 修复：使用正确的医学数据集JOIN关系\n",
    "        for i in range(1, len(tables)):\n",
    "            current_table = tables[i]\n",
    "            prev_table = tables[i-1]\n",
    "            \n",
    "            # 根据预定义的表关系确定JOIN条件\n",
    "            join_condition = None\n",
    "            \n",
    "            # disease -> drug: disease_name = disease_name\n",
    "            if (prev_table == \"disease\" and current_table == \"drug\") or \\\n",
    "               (prev_table == \"drug\" and current_table == \"disease\"):\n",
    "                join_condition = \"disease.disease_name = drug.disease_name\"\n",
    "            \n",
    "            # drug -> institutes: manufacturer = institution_name  \n",
    "            elif (prev_table == \"drug\" and current_table == \"institutes\") or \\\n",
    "                 (prev_table == \"institutes\" and current_table == \"drug\"):\n",
    "                join_condition = \"drug.manufacturer = institutes.institution_name\"\n",
    "            \n",
    "            # disease -> institutes: 多值匹配（research_diseases字段包含疾病名称）\n",
    "            elif (prev_table == \"disease\" and current_table == \"institutes\") or \\\n",
    "                 (prev_table == \"institutes\" and current_table == \"disease\"):\n",
    "                join_condition = \"FIND_IN_SET(disease.disease_name, REPLACE(institutes.research_diseases, '||', ',')) > 0\"\n",
    "            \n",
    "            # 三表JOIN的情况：disease -> drug -> institutes\n",
    "            elif len(tables) == 3 and i == 2:\n",
    "                if \"disease\" in tables and \"drug\" in tables and \"institutes\" in tables:\n",
    "                    # 已经有disease-drug的JOIN，现在添加drug-institutes的JOIN\n",
    "                    join_condition = \"drug.manufacturer = institutes.institution_name\"\n",
    "            \n",
    "            # 如果没有找到合适的JOIN条件，使用默认的业务逻辑\n",
    "            if not join_condition:\n",
    "                print(f\"Warning: No specific join condition found for {prev_table} -> {current_table}\")\n",
    "                # 可以根据具体业务逻辑添加更多JOIN条件\n",
    "                join_condition = f\"{prev_table}.{prev_table}_id = {current_table}.{prev_table}_id\"\n",
    "            \n",
    "            from_clause += f\"\\nINNER JOIN {current_table} ON {join_condition}\"\n",
    "    \n",
    "    sql_parts = [select_clause, from_clause]\n",
    "    \n",
    "    if query_dict.get(\"WHERE\"):\n",
    "        sql_parts.append(f\"WHERE {query_dict['WHERE']}\")\n",
    "    if query_dict.get(\"GROUP BY\"):\n",
    "        sql_parts.append(f\"GROUP BY {', '.join(query_dict['GROUP BY'])}\")\n",
    "    if query_dict.get(\"ORDER BY\"):\n",
    "        order_col, order_type = query_dict[\"ORDER BY\"]\n",
    "        sql_parts.append(f\"ORDER BY {order_col} {order_type}\")\n",
    "    if query_dict.get(\"LIMIT\"):\n",
    "        sql_parts.append(f\"LIMIT {query_dict['LIMIT']}\")\n",
    "    \n",
    "    return \"\\n\".join(sql_parts) + \";\"\n",
    "\n",
    "def generate_schema_sql(schema_dict, table_name=\"Medical_Data\"):\n",
    "    \"\"\"生成建表SQL\"\"\"\n",
    "    columns = []\n",
    "    for col_name, (data_type, description) in schema_dict.items():\n",
    "        comment = f\" COMMENT '{description}'\" if description else \"\"\n",
    "        columns.append(f\"    {col_name} {data_type}{comment}\")\n",
    "    \n",
    "    return f\"CREATE TABLE {table_name} (\\n\" + \",\\n\".join(columns) + \"\\n);\"\n",
    "\n",
    "def save_queries_with_sql(all_queries, output_dir=\"./sql_queries/\"):\n",
    "    \"\"\"保存查询到文件\"\"\"\n",
    "    if not all_queries:\n",
    "        print(\"No queries to save.\")\n",
    "        return 0\n",
    "        \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 按查询类型分组\n",
    "    queries_by_type = {}\n",
    "    for query in all_queries:\n",
    "        query_type = query.get('Type', 'Unknown')\n",
    "        if query_type not in queries_by_type:\n",
    "            queries_by_type[query_type] = []\n",
    "        queries_by_type[query_type].append(query)\n",
    "    \n",
    "    total_saved = 0\n",
    "    \n",
    "    for query_type, queries in queries_by_type.items():\n",
    "        sql_content = \"\"\n",
    "        \n",
    "        for i, query in enumerate(queries):\n",
    "            # 添加默认值\n",
    "            if 'FROM' not in query:\n",
    "                query['FROM'] = ['medical_table']\n",
    "            if 'SELECT' not in query:\n",
    "                query['SELECT'] = ['*']\n",
    "            if 'SCHEMA' not in query:\n",
    "                query['SCHEMA'] = {'id': ['INT', 'Primary key']}\n",
    "            \n",
    "            # 生成SQL\n",
    "            table_name = query['FROM'][0] if len(query['FROM']) == 1 else \"Medical_Data\"\n",
    "            schema_sql = generate_schema_sql(query[\"SCHEMA\"], table_name)\n",
    "            query_sql = generate_sql_query(query)\n",
    "            \n",
    "            # 组合SQL\n",
    "            complete_sql = f\"-- Query {i+1} ({query_type})\\n\"\n",
    "            complete_sql += f\"-- Rows: {query.get('WHERE Total Rows', 'N/A')}\\n\\n\"\n",
    "            complete_sql += schema_sql + \"\\n\\n\"\n",
    "            complete_sql += query_sql + \"\\n\" + \"-\" * 50 + \"\\n\\n\"\n",
    "            \n",
    "            sql_content += complete_sql\n",
    "        \n",
    "        # 保存文件\n",
    "        with open(os.path.join(output_dir, f\"{query_type}.sql\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(sql_content)\n",
    "        \n",
    "        total_saved += len(queries)\n",
    "    \n",
    "    print(f\"Saved {total_saved} queries to {output_dir}\")\n",
    "    return total_saved\n",
    "\n",
    "# 收集所有查询变量\n",
    "def collect_all_queries():\n",
    "    \"\"\"收集环境中的查询变量\"\"\"\n",
    "    all_queries = []\n",
    "    query_vars = ['sf_queries', 'sfj_queries', 'sfw_queries', 'join_queries', \n",
    "                  'topk_queries', 'groupby_queries', 'aggregation_queries',\n",
    "                  'groupby_aggregation_queries', 'groupby_aggregation_topk_queries',\n",
    "                  'sfag_queries'] \n",
    "    \n",
    "    for var_name in query_vars:\n",
    "        if var_name in globals() and globals()[var_name]:\n",
    "            all_queries.extend(globals()[var_name])\n",
    "    \n",
    "    return all_queries\n",
    "\n",
    "# 执行保存\n",
    "try:\n",
    "    if 'all_queries' in globals() and all_queries:\n",
    "        save_queries_with_sql(all_queries)\n",
    "    else:\n",
    "        collected = collect_all_queries()\n",
    "        if collected:\n",
    "            save_queries_with_sql(collected)\n",
    "        else:\n",
    "            print(\"No queries found. Run query generation functions first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922d0ae",
   "metadata": {},
   "source": [
    "### 固定Filter和Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== 医学数据集固定模板查询生成模块 ========================\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "MEDICAL_TEMPLATES = [\n",
    "    # 1个Filter模板 (2/10 = 20%) - 必须包括JOIN\n",
    "    {\n",
    "        \"name\": \"disease_join_analysis\", \n",
    "        \"filters\": [{\"table\": \"disease\", \"attr\": \"disease_type\"}], \n",
    "        \"tables\": [\"disease\", \"drug\"], \n",
    "        \"filter_count\": 1\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"drug_join_analysis\", \n",
    "        \"filters\": [{\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"}], \n",
    "        \"tables\": [\"drug\", \"institutes\"], \n",
    "        \"filter_count\": 1\n",
    "    },\n",
    "    \n",
    "    # 2个Filter模板 (3/10 = 30%) - JOIN的两个表各有一个Filter\n",
    "    {\n",
    "        \"name\": \"disease_drug_matching\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"disease_type\"}, \n",
    "            {\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"drug\"], \n",
    "        \"filter_count\": 2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"drug_institute_analysis\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"drug\", \"attr\": \"prescription_status\"}, \n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_type\"}\n",
    "        ], \n",
    "        \"tables\": [\"drug\", \"institutes\"], \n",
    "        \"filter_count\": 2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disease_institute_research\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"treatments\"}, \n",
    "            {\"table\": \"institutes\", \"attr\": \"research_fields\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"institutes\"], \n",
    "        \"filter_count\": 2\n",
    "    },\n",
    "    \n",
    "    # 3个Filter模板 (3/10 = 30%) - 每个表至少一个Filter\n",
    "    {\n",
    "        \"name\": \"comprehensive_disease_drug\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"disease_type\"}, \n",
    "            {\"table\": \"disease\", \"attr\": \"treatments\"},\n",
    "            {\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"drug\"], \n",
    "        \"filter_count\": 3\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"drug_manufacturer_research\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"drug\", \"attr\": \"administration_route\"}, \n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_type\"},\n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_country\"}\n",
    "        ], \n",
    "        \"tables\": [\"drug\", \"institutes\"], \n",
    "        \"filter_count\": 3\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"three_table_basic\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"disease_type\"}, \n",
    "            {\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"},\n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_type\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"drug\", \"institutes\"], \n",
    "        \"filter_count\": 3\n",
    "    },\n",
    "    \n",
    "    # 4个Filter模板 (1/10 = 10%) - 每个表至少一个Filter\n",
    "    {\n",
    "        \"name\": \"detailed_medical_analysis\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"disease_type\"}, \n",
    "            {\"table\": \"disease\", \"attr\": \"prognosis\"},\n",
    "            {\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"},\n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_type\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"drug\", \"institutes\"], \n",
    "        \"filter_count\": 4\n",
    "    },\n",
    "    \n",
    "    # 5个Filter模板 (1/10 = 10%) - 每个表至少一个Filter\n",
    "    {\n",
    "        \"name\": \"comprehensive_medical_ecosystem\", \n",
    "        \"filters\": [\n",
    "            {\"table\": \"disease\", \"attr\": \"disease_type\"}, \n",
    "            {\"table\": \"disease\", \"attr\": \"treatments\"},\n",
    "            {\"table\": \"drug\", \"attr\": \"pharmaceutical_form\"},\n",
    "            {\"table\": \"drug\", \"attr\": \"prescription_status\"},\n",
    "            {\"table\": \"institutes\", \"attr\": \"institution_type\"}\n",
    "        ], \n",
    "        \"tables\": [\"disease\", \"drug\", \"institutes\"], \n",
    "        \"filter_count\": 5\n",
    "    }\n",
    "]\n",
    "\n",
    "QUERY_TYPES = [\"SF\", \"SFW\", \"SFWT\", \"SFWG\", \"SFWA\", \"SFWGA\", \"SFJ\", \"SFWJ\", \"SFWTJ\", \"SFWGJ\", \"SFWAJ\", \"SFWGAJ\"]\n",
    "\n",
    "# 模板描述映射\n",
    "TEMPLATE_DESCRIPTIONS = {\n",
    "    \"disease_type_analysis\": \"疾病类型分析\",\n",
    "    \"treatment_study\": \"治疗方法研究\", \n",
    "    \"drug_form_analysis\": \"药物剂型分析\",\n",
    "    \"prescription_analysis\": \"处方状态分析\",\n",
    "    \"institution_distribution\": \"医疗机构分布\",\n",
    "    \"research_capacity\": \"科研能力评估\",\n",
    "    \"disease_drug_matching\": \"疾病-药物匹配分析\",\n",
    "    \"manufacturer_analysis\": \"制药企业分析\", \n",
    "    \"disease_research_focus\": \"疾病研究重点\",\n",
    "    \"medical_ecosystem\": \"医疗生态系统分析\",\n",
    "    \"treatment_pipeline\": \"治疗管线分析\"\n",
    "}\n",
    "\n",
    "class MedicalSQLTemplateGenerator:\n",
    "    def __init__(self, tables, attr_value_dict, filter_dict):\n",
    "        self.tables = tables\n",
    "        self.attr_value_dict = attr_value_dict\n",
    "        self.filter_dict = filter_dict\n",
    "        \n",
    "        # 修复：正确定义表之间的JOIN关系\n",
    "        self.join_relationships = {\n",
    "            (\"disease\", \"drug\"): (\"disease_name\", \"disease_name\"),\n",
    "            (\"drug\", \"institutes\"): (\"manufacturer\", \"institution_name\"),\n",
    "            (\"disease\", \"institutes\"): (\"disease_name\", \"research_diseases\")  # 特殊处理\n",
    "        }\n",
    "        \n",
    "        self.table_attrs = {\n",
    "            \"disease\": [\"disease_name\", \"disease_type\", \"pathogenesis\", \"treatments\", \"prognosis\"],\n",
    "            \"drug\": [\"generic_name\", \"pharmaceutical_form\", \"manufacturer\", \"administration_route\", \"prescription_status\"],\n",
    "            \"institutes\": [\"institution_name\", \"institution_type\", \"institution_country\", \"research_fields\", \"key_technologies\"]\n",
    "        }\n",
    "        \n",
    "        self.numerical_attrs = []\n",
    "        self.category_attrs = [\"disease_type\", \"pathogenesis\", \"treatments\", \"prognosis\", \"institution_type\", \n",
    "                              \"pharmaceutical_form\", \"administration_route\", \"prescription_status\"]\n",
    "    \n",
    "    \n",
    "    def validate_template_constraints(self, template):\n",
    "        \"\"\"验证模板是否满足JOIN和Filter分布约束\"\"\"\n",
    "        filters = template[\"filters\"]\n",
    "        tables = template[\"tables\"]\n",
    "        filter_count = template[\"filter_count\"]\n",
    "        \n",
    "        # 统计每个表的filter数量\n",
    "        table_filter_count = {}\n",
    "        for filter_def in filters:\n",
    "            table_name = filter_def[\"table\"]\n",
    "            table_filter_count[table_name] = table_filter_count.get(table_name, 0) + 1\n",
    "        \n",
    "        # 验证约束条件\n",
    "        if filter_count == 1:\n",
    "            # 1个Filter必须包括JOIN\n",
    "            if len(tables) < 2:\n",
    "                return False, \"1-filter template must include JOIN\"\n",
    "        \n",
    "        elif filter_count == 2:\n",
    "            # 2个Filter的JOIN：两个表各有一个Filter\n",
    "            if len(tables) != 2:\n",
    "                return False, \"2-filter template must be 2-table JOIN\"\n",
    "            for table in tables:\n",
    "                if table_filter_count.get(table, 0) < 1:\n",
    "                    return False, f\"2-filter template: table {table} must have at least 1 filter\"\n",
    "        \n",
    "        elif filter_count >= 3:\n",
    "            # 3个及以上Filter：每个JOIN表都至少有一个Filter\n",
    "            for table in tables:\n",
    "                if table_filter_count.get(table, 0) < 1:\n",
    "                    return False, f\"{filter_count}-filter template: table {table} must have at least 1 filter\"\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "    \n",
    "    def get_alternative_filter_values(self, table_name, attr, exclude_values=None):\n",
    "        \"\"\"获取指定属性的备选值\"\"\"\n",
    "        if exclude_values is None:\n",
    "            exclude_values = []\n",
    "            \n",
    "        if table_name not in self.attr_value_dict or attr not in self.attr_value_dict[table_name]:\n",
    "            return []\n",
    "            \n",
    "        values = self.attr_value_dict[table_name][attr]\n",
    "        clean_values = [str(v).strip() for v in values \n",
    "                       if '||' not in str(v) and ',' not in str(v) \n",
    "                       and str(v).strip() and str(v).strip() not in exclude_values]\n",
    "        \n",
    "        return clean_values[:10]  # 返回前10个备选值\n",
    "    \n",
    "    def test_filter_combination_with_values(self, filter_combination, relaxation_level=0):\n",
    "        \"\"\"测试特定Filter值组合的筛选结果数量\"\"\"\n",
    "        conditions = []\n",
    "        tables_involved = set()\n",
    "        \n",
    "        for filter_def in filter_combination:\n",
    "            table_name = filter_def[\"table\"]\n",
    "            filter_attr = filter_def[\"attr\"]\n",
    "            filter_value = filter_def[\"value\"]\n",
    "            tables_involved.add(table_name)\n",
    "            \n",
    "            # 直接使用指定的值生成条件\n",
    "            if filter_attr in [\"research_diseases\", \"treatments\", \"drugs\", \"common_symptoms\", \"complications\", \"research_fields\", \"key_technologies\"]:\n",
    "                if relaxation_level >= 1:\n",
    "                    condition = f\"{table_name}.{filter_attr} LIKE '%{filter_value}%'\"\n",
    "                else:\n",
    "                    condition = f\"{table_name}.{filter_attr} = '{filter_value}'\"\n",
    "            else:\n",
    "                condition = f\"{table_name}.{filter_attr} = '{filter_value}'\"\n",
    "            \n",
    "            conditions.append(condition)\n",
    "        \n",
    "        if not conditions:\n",
    "            return 0, [], list(tables_involved)\n",
    "        \n",
    "        # 使用Filter dict进行更准确的估算\n",
    "        estimated_rows = float('inf')\n",
    "        for filter_def in filter_combination:\n",
    "            table_name = filter_def[\"table\"]\n",
    "            filter_attr = filter_def[\"attr\"]\n",
    "            filter_value = filter_def[\"value\"]\n",
    "            \n",
    "            # 检查这个具体的filter值在filter_dict中的结果\n",
    "            if (table_name in self.filter_dict and \n",
    "                filter_attr in self.filter_dict[table_name]):\n",
    "                \n",
    "                # 寻找匹配的条件\n",
    "                for condition_str, indices in self.filter_dict[table_name][filter_attr].items():\n",
    "                    if filter_value in condition_str:\n",
    "                        estimated_rows = min(estimated_rows, len(indices))\n",
    "                        break\n",
    "        \n",
    "        # 如果没有找到精确匹配，使用保守估算\n",
    "        if estimated_rows == float('inf'):\n",
    "            if len(tables_involved) == 1:\n",
    "                table_rows = len(self.tables.get(list(tables_involved)[0], []))\n",
    "            else:\n",
    "                table_rows = min(len(self.tables.get(t, [])) for t in tables_involved if t in self.tables)\n",
    "            \n",
    "            base_ratio = 0.3 ** len(conditions)\n",
    "            relaxation_bonus = 1.3 ** relaxation_level\n",
    "            estimated_rows = max(1, int(table_rows * base_ratio * relaxation_bonus))\n",
    "        \n",
    "        return estimated_rows, conditions, list(tables_involved)\n",
    "    \n",
    "    def apply_template_filters_with_value_replacement(self, template, min_required_rows=3, min_attempts=10, max_attempts=20):\n",
    "        \"\"\"应用模板Filter，支持动态值替换策略\"\"\"\n",
    "        # 首先验证模板约束\n",
    "        is_valid, validation_msg = self.validate_template_constraints(template)\n",
    "        if not is_valid:\n",
    "            return None, None, None, f\"CONSTRAINT_VIOLATION: {validation_msg}\"\n",
    "        \n",
    "        filters = template[\"filters\"]\n",
    "        tables_involved = template[\"tables\"]\n",
    "        \n",
    "        if not tables_involved:\n",
    "            return None, None, None, \"NO_VALID_TABLES\"\n",
    "        \n",
    "        # 先尝试原始的放宽策略\n",
    "        initial_result = self._try_initial_approach(filters, tables_involved)\n",
    "        \n",
    "        # 如果初始结果满足要求，直接返回\n",
    "        if initial_result and initial_result[2] >= min_required_rows:\n",
    "            return initial_result\n",
    "        \n",
    "        # 如果初始结果小于3条，使用值替换策略（至少尝试min_attempts次）\n",
    "        replacement_result = self._try_value_replacement_strategy(\n",
    "            filters, tables_involved, min_required_rows, min_attempts, max_attempts\n",
    "        )\n",
    "        \n",
    "        # 返回更好的结果\n",
    "        if replacement_result:\n",
    "            return replacement_result\n",
    "        elif initial_result:\n",
    "            return initial_result\n",
    "        else:\n",
    "            return None, None, None, \"ALL_STRATEGIES_FAILED\"\n",
    "    \n",
    "    def _try_initial_approach(self, filters, tables_involved):\n",
    "        \"\"\"尝试初始方法（简单的放宽策略）\"\"\"\n",
    "        for relaxation_level in range(4):\n",
    "            conditions = []\n",
    "            success = True\n",
    "            \n",
    "            for filter_def in filters:\n",
    "                table_name = filter_def[\"table\"]\n",
    "                filter_attr = filter_def[\"attr\"]\n",
    "                \n",
    "                if table_name not in tables_involved:\n",
    "                    success = False\n",
    "                    break\n",
    "                \n",
    "                val, condition = self.get_filter_value(table_name, filter_attr, relaxation_level)\n",
    "                if condition:\n",
    "                    conditions.append(condition)\n",
    "                else:\n",
    "                    if relaxation_level < 3:\n",
    "                        success = False\n",
    "                        break\n",
    "            \n",
    "            if success and len(conditions) >= len(filters) // 2:\n",
    "                if len(tables_involved) == 1:\n",
    "                    table_rows = len(self.tables.get(tables_involved[0], []))\n",
    "                else:\n",
    "                    table_rows = min(len(self.tables.get(t, [])) for t in tables_involved if t in self.tables)\n",
    "                \n",
    "                base_ratio = 0.3 ** len(conditions)\n",
    "                relaxation_bonus = 1.5 ** relaxation_level\n",
    "                estimated_rows = max(1, int(table_rows * base_ratio * relaxation_bonus))\n",
    "                \n",
    "                return list(range(estimated_rows)), conditions, estimated_rows, f\"INITIAL_RELAXATION_{relaxation_level}\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _try_value_replacement_strategy(self, filters, tables_involved, min_required_rows, min_attempts, max_attempts):\n",
    "        \"\"\"尝试值替换策略，确保至少尝试min_attempts次\"\"\"\n",
    "        import itertools\n",
    "        import random\n",
    "        \n",
    "        best_result = None\n",
    "        attempt = 0\n",
    "        successful_attempts = 0  # 真正成功（>=min_required_rows）的尝试次数\n",
    "        all_attempts_results = []  # 记录所有尝试的结果，用于调试\n",
    "        \n",
    "        # 为每个Filter生成候选值\n",
    "        filter_candidates = []\n",
    "        for filter_def in filters:\n",
    "            table_name = filter_def[\"table\"]\n",
    "            attr = filter_def[\"attr\"]\n",
    "            \n",
    "            candidate_values = self.get_alternative_filter_values(table_name, attr)\n",
    "            if not candidate_values:\n",
    "                # 如果没有候选值，使用原始方法\n",
    "                val, _ = self.get_filter_value(table_name, attr, 0)\n",
    "                candidate_values = [val] if val else [\"DEFAULT\"]\n",
    "            \n",
    "            filter_candidates.append({\n",
    "                \"table\": table_name,\n",
    "                \"attr\": attr,\n",
    "                \"values\": candidate_values[:8]  # 增加候选值数量以提供更多组合\n",
    "            })\n",
    "        \n",
    "        # 生成所有可能的值组合\n",
    "        value_combinations = list(itertools.product(\n",
    "            *[fc[\"values\"] for fc in filter_candidates]\n",
    "        ))\n",
    "        \n",
    "        # 随机打乱顺序，避免总是使用相同的组合\n",
    "        random.shuffle(value_combinations)\n",
    "        \n",
    "        # 如果组合数量不足，重复使用组合直到有足够的尝试机会\n",
    "        if len(value_combinations) < max_attempts:\n",
    "            # 重复组合列表，确保有足够的尝试机会\n",
    "            extended_combinations = []\n",
    "            for i in range(max_attempts):\n",
    "                extended_combinations.append(value_combinations[i % len(value_combinations)])\n",
    "            value_combinations = extended_combinations\n",
    "        \n",
    "        # 尝试不同的值组合\n",
    "        for value_combo in value_combinations[:max_attempts]:\n",
    "            attempt += 1\n",
    "            \n",
    "            # 构建当前尝试的Filter组合\n",
    "            current_filters = []\n",
    "            for i, filter_candidate in enumerate(filter_candidates):\n",
    "                current_filters.append({\n",
    "                    \"table\": filter_candidate[\"table\"],\n",
    "                    \"attr\": filter_candidate[\"attr\"],\n",
    "                    \"value\": value_combo[i]\n",
    "                })\n",
    "            \n",
    "            # 测试当前组合\n",
    "            estimated_rows, conditions, tables = self.test_filter_combination_with_values(current_filters)\n",
    "            all_attempts_results.append(estimated_rows)  # 记录所有结果用于调试\n",
    "            \n",
    "            # 检查是否真正成功（>=min_required_rows）\n",
    "            is_successful = estimated_rows >= min_required_rows\n",
    "            if is_successful:\n",
    "                successful_attempts += 1\n",
    "                best_result = (list(range(estimated_rows)), conditions, estimated_rows, attempt, successful_attempts)\n",
    "                \n",
    "                # 只有在至少尝试了min_attempts次，并且找到了成功结果时才可能早期停止\n",
    "                if attempt >= min_attempts:\n",
    "                    break\n",
    "            else:\n",
    "                # 记录最佳结果（即使不满足要求）\n",
    "                if best_result is None or estimated_rows > best_result[2]:\n",
    "                    best_result = (list(range(estimated_rows)), conditions, estimated_rows, attempt, successful_attempts)\n",
    "            \n",
    "            # 强制至少尝试min_attempts次，除非已经找到了满足要求的结果\n",
    "            if attempt < min_attempts:\n",
    "                continue  # 继续尝试\n",
    "        \n",
    "        if best_result:\n",
    "            indices, conditions, estimated_rows, attempts_used, final_successful_count = best_result\n",
    "            \n",
    "            # 生成详细的策略信息\n",
    "            strategy_info = f\"VALUE_REPLACEMENT_{attempts_used}_ATTEMPTS\"\n",
    "            \n",
    "            if final_successful_count > 0:\n",
    "                strategy_info += f\"_SUCCESS_{final_successful_count}\"\n",
    "            else:\n",
    "                strategy_info += f\"_NOSUCCESS_BEST_{estimated_rows}\"\n",
    "                \n",
    "            # 添加调试信息\n",
    "            max_result = max(all_attempts_results) if all_attempts_results else 0\n",
    "            min_result = min(all_attempts_results) if all_attempts_results else 0\n",
    "            strategy_info += f\"_RANGE_{min_result}TO{max_result}\"\n",
    "            \n",
    "            return indices, conditions, estimated_rows, strategy_info\n",
    "        else:\n",
    "            return None, None, None, f\"VALUE_REPLACEMENT_FAILED_AFTER_{attempt}_ATTEMPTS_MAX_{max(all_attempts_results) if all_attempts_results else 0}\"\n",
    "    \n",
    "    def apply_template_filters(self, template, max_relaxation=3):\n",
    "        \"\"\"应用模板Filter，支持多级放宽策略和约束验证\"\"\"\n",
    "        # 使用新的值替换策略，确保结果<3条时至少尝试10次\n",
    "        return self.apply_template_filters_with_value_replacement(template, min_required_rows=3, min_attempts=40, max_attempts=50)\n",
    "    \n",
    "    def get_filter_value(self, table_name, attr, relaxation_level=0):\n",
    "        \"\"\"智能获取模板Filter值，支持多级放宽策略\"\"\"\n",
    "        if table_name not in self.attr_value_dict or attr not in self.attr_value_dict[table_name]:\n",
    "            return None, None\n",
    "            \n",
    "        values = self.attr_value_dict[table_name][attr]\n",
    "        if not values:\n",
    "            return None, None\n",
    "        \n",
    "        # 过滤掉包含分隔符的复合值，确保使用单一值\n",
    "        clean_values = [str(v).strip() for v in values if '||' not in str(v) and ',' not in str(v) and str(v).strip()]\n",
    "        if not clean_values:\n",
    "            return None, None\n",
    "        \n",
    "        # 由于没有数值属性，只处理文本属性\n",
    "        val = random.choice(clean_values)\n",
    "        \n",
    "        # 针对多值属性，使用包含匹配（更宽松）\n",
    "        if attr in [\"research_diseases\", \"treatments\", \"drugs\", \"common_symptoms\", \"complications\", \"research_fields\", \"key_technologies\"]:\n",
    "            if relaxation_level >= 1:\n",
    "                return val, f\"{table_name}.{attr} LIKE '%{val}%'\"\n",
    "            else:\n",
    "                return val, f\"{table_name}.{attr} = '{val}'\"\n",
    "        else:\n",
    "            return val, f\"{table_name}.{attr} = '{val}'\"\n",
    "    \n",
    "     def generate_join_clause(self, tables):\n",
    "        \"\"\"生成正确的JOIN子句\"\"\"\n",
    "        if len(tables) <= 1:\n",
    "            return \"\"\n",
    "        \n",
    "        join_parts = []\n",
    "        \n",
    "        for i in range(1, len(tables)):\n",
    "            current_table = tables[i]\n",
    "            join_condition = None\n",
    "            \n",
    "            # 寻找当前表与之前任一表的JOIN关系\n",
    "            for prev_idx in range(i):\n",
    "                prev_table = tables[prev_idx]\n",
    "                \n",
    "                # 检查直接的JOIN关系\n",
    "                for (t1, t2), (key1, key2) in self.join_relationships.items():\n",
    "                    if (prev_table == t1 and current_table == t2):\n",
    "                        if key2 == \"research_diseases\":\n",
    "                            # 特殊处理：research_diseases是多值字段\n",
    "                            join_condition = f\"FIND_IN_SET({prev_table}.{key1}, REPLACE({current_table}.{key2}, '||', ',')) > 0\"\n",
    "                        else:\n",
    "                            join_condition = f\"{prev_table}.{key1} = {current_table}.{key2}\"\n",
    "                        break\n",
    "                    elif (prev_table == t2 and current_table == t1):\n",
    "                        if key1 == \"research_diseases\":\n",
    "                            # 特殊处理：research_diseases是多值字段  \n",
    "                            join_condition = f\"FIND_IN_SET({current_table}.{key2}, REPLACE({prev_table}.{key1}, '||', ',')) > 0\"\n",
    "                        else:\n",
    "                            join_condition = f\"{prev_table}.{key2} = {current_table}.{key1}\"\n",
    "                        break\n",
    "                \n",
    "                if join_condition:\n",
    "                    break\n",
    "            \n",
    "            # 如果没有找到直接关系，尝试间接关系\n",
    "            if not join_condition and len(tables) == 3:\n",
    "                # 三表JOIN的特殊处理：disease -> drug -> institutes\n",
    "                if i == 2 and tables == [\"disease\", \"drug\", \"institutes\"]:\n",
    "                    join_condition = \"drug.manufacturer = institutes.institution_name\"\n",
    "                elif i == 2 and tables == [\"disease\", \"institutes\", \"drug\"]:\n",
    "                    join_condition = \"institutes.institution_name = drug.manufacturer\"\n",
    "            \n",
    "            if join_condition:\n",
    "                join_parts.append(f\"INNER JOIN {current_table} ON {join_condition}\")\n",
    "            else:\n",
    "                # 最后的备选方案：使用业务主键\n",
    "                print(f\"Warning: Using fallback join for {current_table}\")\n",
    "                join_parts.append(f\"INNER JOIN {current_table} ON {tables[0]}.disease_name = {current_table}.disease_name\")\n",
    "        \n",
    "        return \"\\n\" + \"\\n\".join(join_parts) if join_parts else \"\"\n",
    "    \n",
    "    def generate_query_sql(self, template, query_type, query_id):\n",
    "        \"\"\"生成医学查询SQL，支持失败处理和值替换策略\"\"\"\n",
    "        # 应用模板Filter\n",
    "        result = self.apply_template_filters(template)\n",
    "        \n",
    "        # 处理生成失败的情况\n",
    "        if result[0] is None or result[1] is None:\n",
    "            # 检查第四个元素是字符串还是其他类型\n",
    "            error_info = result[3]\n",
    "            if isinstance(error_info, str) and (\n",
    "                error_info in [\"ALL_STRATEGIES_FAILED\", \"NO_VALID_TABLES\"] or \n",
    "                error_info.startswith(\"CONSTRAINT_VIOLATION\") or\n",
    "                error_info.startswith(\"VALUE_REPLACEMENT_FAILED\")\n",
    "            ):\n",
    "                return None  # 简单跳过失败的查询\n",
    "            else:\n",
    "                return None  # 其他类型的失败也跳过\n",
    "        \n",
    "        indices, conditions, estimated_rows, strategy_info = result\n",
    "        \n",
    "        # 获取涉及的表\n",
    "        tables = template[\"tables\"]\n",
    "        \n",
    "        # 强制所有查询都是JOIN查询（根据用户要求）\n",
    "        is_join = True\n",
    "        \n",
    "        # 选择显示列\n",
    "        select_attrs = []\n",
    "        for table in tables[:2]:\n",
    "            table_attrs = self.table_attrs.get(table, [])[:3]\n",
    "            for attr in table_attrs:\n",
    "                select_attrs.append(f\"{table}.{attr}\")\n",
    "        \n",
    "        select_clause = f\"SELECT {', '.join(select_attrs[:4])}\"\n",
    "        from_clause = f\"FROM {tables[0]}\" + self.generate_join_clause(tables)\n",
    "        where_clause = f\"WHERE {' AND '.join(conditions)}\" if conditions else \"\"\n",
    "        \n",
    "        sql_parts = [select_clause, from_clause]\n",
    "        if where_clause:\n",
    "            sql_parts.append(where_clause)\n",
    "        \n",
    "        # 根据查询类型添加子句\n",
    "        base_type = query_type.rstrip('J')\n",
    "        \n",
    "        if base_type == \"SFWT\":\n",
    "            # 由于没有数值属性，使用字符串排序\n",
    "            order_attrs = []\n",
    "            for table in tables:\n",
    "                for attr in self.table_attrs.get(table, []):\n",
    "                    if attr not in [\"ID\"]:  # 排除ID字段\n",
    "                        order_attrs.append(f\"{table}.{attr}\")\n",
    "            \n",
    "            if order_attrs:\n",
    "                order_col = random.choice(order_attrs)\n",
    "                sql_parts.append(f\"ORDER BY {order_col} {random.choice(['ASC', 'DESC'])}\")\n",
    "                limit_value = random.choice([5, 10, 15])\n",
    "                sql_parts.append(f\"LIMIT {limit_value}\")\n",
    "                # 对于TOP-K查询，实际结果可能少于估算值\n",
    "                estimated_rows = min(estimated_rows, limit_value)\n",
    "        \n",
    "        elif base_type in [\"SFWG\", \"SFWGA\"]:\n",
    "            category_attrs = []\n",
    "            for table in tables:\n",
    "                for attr in self.table_attrs.get(table, []):\n",
    "                    if attr in self.category_attrs:\n",
    "                        category_attrs.append(f\"{table}.{attr}\")\n",
    "            \n",
    "            if category_attrs:\n",
    "                group_col = random.choice(category_attrs)\n",
    "                sql_parts.append(f\"GROUP BY {group_col}\")\n",
    "                \n",
    "                if base_type == \"SFWGA\":\n",
    "                    sql_parts[0] = f\"SELECT {group_col}, COUNT(*)\"\n",
    "                \n",
    "                 # GROUP BY查询的结果行数通常会减少\n",
    "                estimated_rows = max(1, estimated_rows // 3)\n",
    "        \n",
    "        elif base_type == \"SFWA\":\n",
    "            sql_parts[0] = \"SELECT COUNT(*)\"\n",
    "            # 聚合查询只返回一行\n",
    "            estimated_rows = 1\n",
    "        \n",
    "        # 生成完整的查询字符串\n",
    "        query_sql = \"\\n\".join(sql_parts) + \";\"\n",
    "        \n",
    "        # 生成Schema\n",
    "        schema_parts = []\n",
    "        for table in tables:\n",
    "            attrs = self.table_attrs.get(table, [])\n",
    "            columns = [f\"    {table}_id INTEGER PRIMARY KEY\"]\n",
    "            \n",
    "            for attr in attrs:\n",
    "                # 由于没有数值属性，所有属性都是VARCHAR\n",
    "                columns.append(f\"    {attr} VARCHAR(255)\")\n",
    "            \n",
    "            schema = f\"CREATE TABLE {table} (\\n\" + \",\\n\".join(columns) + \"\\n);\"\n",
    "            schema_parts.append(schema)\n",
    "        \n",
    "        schema_sql = \"\\n\\n\".join(schema_parts)\n",
    "        \n",
    "        # 组合完整输出\n",
    "        filter_info = \", \".join([f\"{f['table']}.{f['attr']}\" for f in template[\"filters\"]])\n",
    "        output = f\"-- Query {query_id} - {query_type}\\n\"\n",
    "        output += f\"-- Tables: {', '.join(tables)}\\n\"\n",
    "        output += f\"-- Filters: {filter_info}\\n\"\n",
    "        output += f\"-- Filter Count: {template['filter_count']}\\n\"\n",
    "        \n",
    "        # 根据策略类型显示详细信息\n",
    "        if isinstance(strategy_info, str):\n",
    "            if strategy_info.startswith(\"VALUE_REPLACEMENT\"):\n",
    "                # 解析策略信息\n",
    "                parts = strategy_info.split(\"_\")\n",
    "                attempts = parts[2] if len(parts) > 2 else \"N/A\"\n",
    "                \n",
    "                if \"_SUCCESS_\" in strategy_info:\n",
    "                    success_count = strategy_info.split(\"_SUCCESS_\")[1].split(\"_\")[0]\n",
    "                    range_info = \"\"\n",
    "                    if \"_RANGE_\" in strategy_info:\n",
    "                        range_part = strategy_info.split(\"_RANGE_\")[1]\n",
    "                        range_info = f\" (range: {range_part.replace('TO', '-')})\"\n",
    "                    output += f\"-- Estimated Result Rows: {estimated_rows} (Value replacement: {attempts} attempts, {success_count} successful{range_info})\\n\"\n",
    "                elif \"_NOSUCCESS_\" in strategy_info:\n",
    "                    best_result = strategy_info.split(\"_NOSUCCESS_BEST_\")[1].split(\"_\")[0] if \"_NOSUCCESS_BEST_\" in strategy_info else \"N/A\"\n",
    "                    range_info = \"\"\n",
    "                    if \"_RANGE_\" in strategy_info:\n",
    "                        range_part = strategy_info.split(\"_RANGE_\")[1]\n",
    "                        range_info = f\" (range: {range_part.replace('TO', '-')})\"\n",
    "                    output += f\"-- Estimated Result Rows: {estimated_rows} (Value replacement: {attempts} attempts, 0 successful, best: {best_result}{range_info})\\n\"\n",
    "                elif \"_BEST_OF_\" in strategy_info:\n",
    "                    total_attempts = strategy_info.split(\"_BEST_OF_\")[1].split(\"_\")[0] if \"_BEST_OF_\" in strategy_info else attempts\n",
    "                    output += f\"-- Estimated Result Rows: {estimated_rows} (Value replacement: best of {total_attempts} attempts, 0 successful)\\n\"\n",
    "                else:\n",
    "                    output += f\"-- Estimated Result Rows: {estimated_rows} (Value replacement: {attempts} attempts)\\n\"\n",
    "            elif strategy_info.startswith(\"INITIAL_RELAXATION\"):\n",
    "                relaxation_level = strategy_info.split(\"_\")[-1]\n",
    "                output += f\"-- Estimated Result Rows: {estimated_rows} (Initial approach: relaxation level {relaxation_level})\\n\"\n",
    "            else:\n",
    "                output += f\"-- Estimated Result Rows: {estimated_rows} (Strategy: {strategy_info})\\n\"\n",
    "        else:\n",
    "            output += f\"-- Estimated Result Rows: {estimated_rows}\\n\"\n",
    "        \n",
    "        output += \"\\n\"\n",
    "        output += schema_sql + \"\\n\\n\"\n",
    "        output += query_sql + \"\\n\\n\"\n",
    "        output += \"-\" * 40 + \"\\n\\n\"\n",
    "        \n",
    "        return output\n",
    "\n",
    "def generate_medical_template_queries():\n",
    "    base_dir = \"./Medical_Template_Queries/\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    generator = MedicalSQLTemplateGenerator(tables, attr_value_dict, filter_dict)\n",
    "    total_generated = 0\n",
    "    \n",
    "    # 为每个模板创建独立文件夹\n",
    "    for template in MEDICAL_TEMPLATES:\n",
    "        template_dir = os.path.join(base_dir, template[\"name\"])\n",
    "        os.makedirs(template_dir, exist_ok=True)\n",
    "        \n",
    "        is_multi_table = len(template.get(\"tables\", [])) > 1\n",
    "        query_types = [\"SF\", \"SFW\", \"SFWT\", \"SFWG\", \"SFWA\", \"SFAG\"] + ([\"SFJ\", \"SFWJ\", \"SFWTJ\", \"SFWGJ\", \"SFWAJ\", \"SFAGJ\"] if is_multi_table else [])\n",
    "        \n",
    "        # 为每个查询类型生成独立文件\n",
    "        for qtype in query_types:\n",
    "            sql_content = []\n",
    "            \n",
    "            # 简化的文件头部\n",
    "            header = f\"-- {template['name']} - {qtype}\\n\"\n",
    "            header += \"-- \" + \"=\" * 40 + \"\\n\\n\"\n",
    "            sql_content.append(header)\n",
    "            \n",
    "            # 生成查询实例\n",
    "            query_id = 1\n",
    "            generated = 0\n",
    "            attempts = 0\n",
    "            \n",
    "            while generated < 6 and attempts < 18:\n",
    "                attempts += 1\n",
    "                sql = generator.generate_query_sql(template, qtype, query_id)\n",
    "                \n",
    "                if sql and \"[GENERATION FAILED]\" not in sql:\n",
    "                    sql_content.append(sql)\n",
    "                    generated += 1\n",
    "                    total_generated += 1\n",
    "                    query_id += 1\n",
    "            \n",
    "            # 保存文件\n",
    "            filename = os.path.join(template_dir, f\"{qtype}.sql\")\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"\".join(sql_content))\n",
    "    \n",
    "    return total_generated\n",
    "\n",
    "# 执行生成\n",
    "try:\n",
    "    if 'tables' in globals() and 'attr_value_dict' in globals() and 'filter_dict' in globals():\n",
    "        total_queries = generate_medical_template_queries()\n",
    "        print(f\"Generated {total_queries} medical queries in ./Medical_Template_Queries/\")\n",
    "    else:\n",
    "        print(\"Required variables not found. Run data loading steps first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
