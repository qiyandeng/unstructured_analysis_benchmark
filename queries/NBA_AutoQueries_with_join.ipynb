{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import openpyxl\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义输入输出路径，并加载数据\n",
    "- `dataset_dirs`：三个NBA数据集表格路径\n",
    "- `statistics_output_dir`：统计数据表输出路径，包括属性值、选择率、基数\n",
    "- `valid_where_output_dir`：所有有效谓词组合的输出路径\n",
    "- **注意**：支持 .csv 格式，自动处理编码问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 定义输入输出路径，并加载数据\n",
    "# dataset_dirs：四个表的文件路径\n",
    "# statistics_output_dir：统计数据表输出路径，包括属性值、选择率、基数\n",
    "# valid_where_output_dir：所有有效谓词组合的输出路径\n",
    "\n",
    "# 数据集路径配置\n",
    "dataset_dirs = {\n",
    "    \"city\": \"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/city.csv\",\n",
    "    \"owner\": \"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/owner.csv\", \n",
    "    \"team\": \"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/team.csv\",\n",
    "    \"player\": \"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/player.csv\"\n",
    "}\n",
    "\n",
    "statistics_output_dir = r\"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/NBA_Statistics.csv\"\n",
    "valid_where_output_dir = r\"/data2/liujinqi/Benchmark/Query/NBA_AutoConstruct/JOIN/NBA_valid_WHERE.json\"\n",
    "\n",
    "# 读取所有表的数据，保持独立\n",
    "dataframes = {}\n",
    "for table_name, file_path in dataset_dirs.items():\n",
    "    try:\n",
    "        if table_name == \"player\":\n",
    "            # player1.csv可能有编码问题，尝试不同编码\n",
    "            try:\n",
    "                dataframes[table_name] = pd.read_csv(file_path, encoding='utf-8')\n",
    "            except:\n",
    "                dataframes[table_name] = pd.read_csv(file_path, encoding='latin1')\n",
    "        else:\n",
    "            dataframes[table_name] = pd.read_csv(file_path, encoding='utf-8')\n",
    "        \n",
    "        # 清理player表的空列\n",
    "        if table_name == \"player\":\n",
    "            # 删除空列或无用列\n",
    "            cols_to_drop = [col for col in dataframes[table_name].columns if col.startswith('_') or col == '']\n",
    "            dataframes[table_name] = dataframes[table_name].drop(columns=cols_to_drop, errors='ignore')\n",
    "            \n",
    "        print(f\"成功加载 {table_name}: {len(dataframes[table_name])} 行, {len(dataframes[table_name].columns)} 列\")\n",
    "        print(f\"  列名: {list(dataframes[table_name].columns)}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"警告: 文件不存在 {file_path}\")\n",
    "        dataframes[table_name] = pd.DataFrame()\n",
    "\n",
    "# 定义表之间的JOIN关系\n",
    "join_relationships = {\n",
    "    # (表1, 表2): (表1的关联字段, 表2的关联字段)\n",
    "    (\"owner\", \"team\"): (\"NBA_team\", \"team_name\"),\n",
    "    (\"team\", \"city\"): (\"location\", \"city_name\"),\n",
    "    (\"player\", \"team\"): (\"team\", \"team_name\")\n",
    "}\n",
    "\n",
    "# 定义表到表的路径（用于复杂JOIN）\n",
    "table_paths = {\n",
    "    (\"owner\", \"city\"): [(\"owner\", \"team\"), (\"team\", \"city\")],\n",
    "    (\"player\", \"city\"): [(\"player\", \"team\"), (\"team\", \"city\")],\n",
    "    (\"owner\", \"player\"): [(\"owner\", \"team\"), (\"team\", \"player\")]\n",
    "}\n",
    "\n",
    "print(\"表关系定义完成:\")\n",
    "for (t1, t2), (f1, f2) in join_relationships.items():\n",
    "    print(f\"  {t1}.{f1} = {t2}.{f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义属性，方便后面按不同属性类型设计不同的构造方法\n",
    "- `attr_desc_dict`：全部属性的集合，以及对应的自然语言描述\n",
    "- `players_attributes`、`teams_attributes`、`games_attributes`：各表特有属性\n",
    "- `non_numerical_attr`：非数值属性的集合\n",
    "- `numerical_attr`：数值属性的集合（年龄、得分、助攻等）\n",
    "- `category_attr`：固定类别的属性\n",
    "- `multi_value_attributes`：多值的属性，用\"||\"分隔或者逗号分隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 定义属性，方便后面按不同属性类型设计不同的构造方法\n",
    "# attr_desc_dict：全部属性的集合，以及对应的自然语言描述\n",
    "# city_attributes、owner_attributes、team_attributes、player_attributes：各表特有属性\n",
    "# non_numerical_attr：非数值属性的集合\n",
    "# numerical_attr：数值属性的集合\n",
    "# category_attr：固定类别的属性\n",
    "# multi_value_attributes：多值的属性，用\"||\"分隔或者逗号分隔\n",
    "\n",
    "attr_desc_dict = {\n",
    "    # City表属性\n",
    "    \"city_name\": \"\", \"state_name\": \"\", \"population\": \"\", \"area\": \"\", \"gdp\": \"\", \"file\": \"\",\n",
    "    \n",
    "    # Owner表属性  \n",
    "    \"name\": \"\", \"age\": \"\", \"nationality\": \"\", \"NBA_team\": \"\", \"own_year\": \"\", \"file\": \"\",\n",
    "    \n",
    "    # Team表属性\n",
    "    \"team_name\": \"\", \"founded_year\": \"\", \"location\": \"\", \"ownership\": \"\", \"championship\": \"\", \"file\": \"\",\n",
    "    \n",
    "    # Player表属性\n",
    "    \"name\": \"\", \"birth_date\": \"\", \"nationality\": \"\", \"age\": \"\", \"team\": \"\", \"position\": \"\", \n",
    "    \"draft_pick\": \"\", \"draft_year\": \"\", \"college\": \"\", \"nba_championships\": \"\", \"mvp_awards\": \"\", \n",
    "    \"olympic_gold_medals\": \"\", \"fiba_world_cup\": \"\", \"file\": \"\"\n",
    "}\n",
    "\n",
    "# 根据实际数据结构定义各表属性\n",
    "city_attributes = list(dataframes[\"city\"].columns) if \"city\" in dataframes and not dataframes[\"city\"].empty else []\n",
    "owner_attributes = list(dataframes[\"owner\"].columns) if \"owner\" in dataframes and not dataframes[\"owner\"].empty else []\n",
    "team_attributes = list(dataframes[\"team\"].columns) if \"team\" in dataframes and not dataframes[\"team\"].empty else []\n",
    "player_attributes = list(dataframes[\"player\"].columns) if \"player\" in dataframes and not dataframes[\"player\"].empty else []\n",
    "\n",
    "table_attributes = {\n",
    "    \"city\": {attr: attr_desc_dict.get(attr, \"\") for attr in city_attributes},\n",
    "    \"owner\": {attr: attr_desc_dict.get(attr, \"\") for attr in owner_attributes},\n",
    "    \"team\": {attr: attr_desc_dict.get(attr, \"\") for attr in team_attributes},\n",
    "    \"player\": {attr: attr_desc_dict.get(attr, \"\") for attr in player_attributes}\n",
    "}\n",
    "\n",
    "print(\"各表属性:\")\n",
    "for table_name, attrs in table_attributes.items():\n",
    "    print(f\"{table_name}: {list(attrs.keys())}\")\n",
    "\n",
    "non_numerical_attr_list = [\n",
    "    \"city_name\", \"state_name\", \"name\", \"nationality\", \"NBA_team\", \"team_name\", \n",
    "    \"location\", \"ownership\", \"birth_date\", \"position\", \"college\", \"file\"\n",
    "]\n",
    "\n",
    "numerical_attr_list = [\n",
    "    \"population\", \"area\", \"gdp\", \"age\", \"own_year\", \"founded_year\", \"championship\",\n",
    "    \"draft_pick\", \"draft_year\", \"nba_championships\", \"mvp_awards\", \n",
    "    \"olympic_gold_medals\", \"fiba_world_cup\"\n",
    "]\n",
    "\n",
    "multi_value_attributes_list = [\n",
    "    # 这个数据集中没有明显的多值属性，保留空列表\n",
    "]\n",
    "\n",
    "category_attr_list = [\n",
    "    \"state_name\", \"nationality\", \"team_name\", \"location\", \"position\", \"college\"\n",
    "]\n",
    "\n",
    "nba_join_relationships = {\n",
    "    # (表1, 表2): (表1的关联字段, 表2的关联字段)\n",
    "    (\"owner\", \"team\"): (\"team\", \"team_name\"),           # owner的team字段关联team的team_name字段\n",
    "    (\"team\", \"city\"): (\"city\", \"city\"),                 # team的city字段关联city的city字段  \n",
    "    (\"player\", \"team\"): (\"team\", \"team_name\")           # player的team字段关联team的team_name字段\n",
    "}\n",
    "\n",
    "# 按表分组 - 基于实际列名\n",
    "non_numerical_attr = {}\n",
    "numerical_attr = {}\n",
    "multi_value_attributes = {}\n",
    "category_attr = {}\n",
    "\n",
    "for table_name, attrs in table_attributes.items():\n",
    "    non_numerical_attr[table_name] = [attr for attr in attrs.keys() if attr in non_numerical_attr_list]\n",
    "    numerical_attr[table_name] = [attr for attr in attrs.keys() if attr in numerical_attr_list]\n",
    "    multi_value_attributes[table_name] = [attr for attr in attrs.keys() if attr in multi_value_attributes_list]\n",
    "    category_attr[table_name] = [attr for attr in attrs.keys() if attr in category_attr_list]\n",
    "\n",
    "print(\"\\n属性分类完成:\")\n",
    "for table_name in table_attributes.keys():\n",
    "    print(f\"{table_name}:\")\n",
    "    print(f\"  非数值属性: {non_numerical_attr[table_name]}\")\n",
    "    print(f\"  数值属性: {numerical_attr[table_name]}\")\n",
    "    print(f\"  类别属性: {category_attr[table_name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成统计信息\n",
    "- 属性 | 属性值 | 选择率 | 基数\n",
    "- 用于后续构造 Filter\n",
    "- 输出CSV格式，类似于原始统计表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nba_statistics(dataframes):\n",
    "    combined_statistics = pd.DataFrame()\n",
    "    \n",
    "    for table_name, df in tqdm(dataframes.items(), desc=\"生成统计信息\"):\n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "        for column in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性\", leave=False):\n",
    "            if column not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # 检查是否为多值属性\n",
    "            if column in multi_value_attributes_list:\n",
    "                # 处理多值属性：只统计拆分后的单个值\n",
    "                all_values = []\n",
    "                total_rows = len(df)\n",
    "                \n",
    "                for cell in df[column].dropna():\n",
    "                    cell_str = str(cell)\n",
    "                    if '||' in cell_str:\n",
    "                        # 拆分||分隔的值\n",
    "                        split_values = [v.strip() for v in cell_str.split('||') if v.strip()]\n",
    "                        all_values.extend(split_values)\n",
    "                    elif ',' in cell_str:\n",
    "                        # 拆分逗号分隔的值\n",
    "                        split_values = [v.strip() for v in cell_str.split(',') if v.strip()]\n",
    "                        all_values.extend(split_values)\n",
    "                    else:\n",
    "                        all_values.append(cell_str.strip())\n",
    "                \n",
    "                # 统计拆分后的单个值\n",
    "                value_counts = pd.Series(all_values).value_counts()\n",
    "                # 计算selectivity：每个值出现的次数 / 总行数\n",
    "                selectivities = (value_counts / total_rows).round(3)\n",
    "            else:\n",
    "                # 普通属性的处理\n",
    "                value_counts = df[column].value_counts()\n",
    "                selectivities = df[column].value_counts(normalize=True).round(3)\n",
    "            \n",
    "            null_count = df[column].isnull().sum()\n",
    "            \n",
    "            column_stats = pd.DataFrame({\n",
    "                f\"{table_name}.{column}\": list(value_counts.index) + [\"(null)\"],\n",
    "                'Count': list(value_counts.values) + [null_count],\n",
    "                'Selectivity': list(selectivities.values) + [round(null_count / len(df), 3)]\n",
    "            })\n",
    "            \n",
    "            if combined_statistics.empty:\n",
    "                combined_statistics = column_stats\n",
    "            else:\n",
    "                combined_statistics = pd.concat([combined_statistics, column_stats], axis=1)\n",
    "    \n",
    "    return combined_statistics\n",
    "\n",
    "nba_statistics = generate_nba_statistics(dataframes)\n",
    "nba_statistics.to_csv(statistics_output_dir, index=False, encoding='utf-8')\n",
    "print(f\"统计信息已保存到: {statistics_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义查询构造参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 定义查询构造参数\n",
    "\n",
    "max_filters = 3\n",
    "min_rows = 2  # NBA数据相对较少，降低最小行数要求\n",
    "max_select = 4\n",
    "limit_list = [1, 2, 3, 5, 8, 10, 15]\n",
    "\n",
    "# 各类查询数量\n",
    "sample_sf = 10         # SELECT FROM (单表)\n",
    "sample_sfj = 10        # SELECT FROM JOIN\n",
    "sample_sfw = 10        # SELECT FROM WHERE (单表)\n",
    "sample_sfwj = 100       # SELECT FROM WHERE JOIN\n",
    "sample_sfwt = 15       # SELECT FROM WHERE TOP-K (单表)\n",
    "sample_sfwtj = 20      # SELECT FROM WHERE TOP-K JOIN\n",
    "sample_sfwg = 15       # SELECT FROM WHERE GROUP BY (单表)\n",
    "sample_sfwgj = 20      # SELECT FROM WHERE GROUP BY JOIN\n",
    "sample_sfwa = 15       # SELECT FROM WHERE AGGREGATION (单表)\n",
    "sample_sfwaj = 20      # SELECT FROM WHERE AGGREGATION JOIN\n",
    "sample_sfwga = 20      # SELECT FROM WHERE GROUP BY AGGREGATION (单表)\n",
    "sample_sfwgaj = 25     # SELECT FROM WHERE GROUP BY AGGREGATION JOIN\n",
    "sample_sfwgat = 15     # SELECT FROM WHERE GROUP BY AGGREGATION TOP-K (单表)\n",
    "sample_sfwgatj = 20    # SELECT FROM WHERE GROUP BY AGGREGATION TOP-K JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义Filter执行方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 定义Filter执行方法\n",
    "\n",
    "def non_numerical_equal_to(value, condition):\n",
    "    try:\n",
    "        return str(value).lower().strip() == str(condition).lower().strip()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def non_numerical_equal_to_with_split(cell, condition):\n",
    "    if pd.isna(cell):\n",
    "        return False\n",
    "    cell_str = str(cell)\n",
    "    if '||' in cell_str:\n",
    "        return condition in [v.strip() for v in cell_str.split('||')]\n",
    "    elif ',' in cell_str:\n",
    "        return condition in [v.strip() for v in cell_str.split(',')]\n",
    "    return non_numerical_equal_to(cell, condition)\n",
    "\n",
    "def number_greater_than(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) > float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_less_than(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) < float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_equal_to(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) == float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_greater_equal(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) >= float(condition)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def number_less_equal(value, condition):\n",
    "    if pd.isna(value):\n",
    "        value = 0\n",
    "    try:\n",
    "        return float(value) <= float(condition)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 均匀采样函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 均匀采样函数\n",
    "\n",
    "def balanced_sample(filters, sample_size=60, random_seed=None):\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    if len(filters) <= sample_size:\n",
    "        return filters\n",
    "    \n",
    "    table_to_filters = defaultdict(list)\n",
    "    for filter_item in filters:\n",
    "        table = filter_item[0]\n",
    "        table_to_filters[table].append(filter_item)\n",
    "    \n",
    "    tables = list(table_to_filters.keys())\n",
    "    per_table = sample_size // len(tables)\n",
    "    remainder = sample_size % len(tables)\n",
    "    \n",
    "    sampled_filters = []\n",
    "    for i, table in enumerate(tables):\n",
    "        table_filters = table_to_filters[table]\n",
    "        table_sample_size = per_table + (1 if i < remainder else 0)\n",
    "        table_sample_size = min(table_sample_size, len(table_filters))\n",
    "        \n",
    "        sampled = random.sample(table_filters, table_sample_size)\n",
    "        sampled_filters.extend(sampled)\n",
    "    \n",
    "    return sampled_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 汇总可取属性值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 汇总可取属性值\n",
    "\n",
    "def get_sample_values_by_selectivity(dataframes, min_rows=2, max_rows=None):\n",
    "    \"\"\"\n",
    "    根据selectivity获取属性值，确保生成的条件有意义\n",
    "    \"\"\"\n",
    "    attr_value_dict = {}\n",
    "    \n",
    "    for table_name, df in tqdm(dataframes.items(), desc=\"获取属性值\"):\n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "        attr_value_dict[table_name] = {}\n",
    "        total_rows = len(df)\n",
    "        if max_rows is None:\n",
    "            max_rows = total_rows // 2  # 默认最大返回一半行数\n",
    "        \n",
    "        for attr in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性值\", leave=False):\n",
    "            if attr not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            non_null_values = df[attr].dropna()\n",
    "            if len(non_null_values) == 0:\n",
    "                continue\n",
    "                \n",
    "            values_list = []\n",
    "            \n",
    "            if attr in numerical_attr_list:\n",
    "                try:\n",
    "                    # 更严格的数值转换和清理\n",
    "                    numeric_values = pd.to_numeric(non_null_values, errors='coerce').dropna()\n",
    "                    \n",
    "                    # 检查数据质量\n",
    "                    if len(numeric_values) == 0:\n",
    "                        print(f\"    {table_name}.{attr}: 无法转换为数值，跳过\")\n",
    "                        continue\n",
    "                    \n",
    "                    # 检查数据类型一致性\n",
    "                    original_count = len(non_null_values)\n",
    "                    numeric_count = len(numeric_values)\n",
    "                    if numeric_count < original_count * 0.8:  # 如果80%以上的数据无法转换为数值\n",
    "                        print(f\"    {table_name}.{attr}: 数据质量差({numeric_count}/{original_count}可转换)，当作文本处理\")\n",
    "                        values_list = []  # 标记为处理失败，后续当文本处理\n",
    "                    else:\n",
    "                        # 数据质量好，继续处理\n",
    "                        numeric_values = pd.to_numeric(non_null_values, errors='coerce').dropna()\n",
    "                        if len(numeric_values) > 0:\n",
    "                            # 检查是否为整数类型的属性\n",
    "                            integer_attrs = [\"population\", \"area\", \"age\", \"own_year\", \"founded_year\", \n",
    "                                            \"championship\", \"draft_pick\", \"draft_year\", \"nba_championships\", \n",
    "                                            \"mvp_awards\", \"olympic_gold_medals\", \"fiba_world_cup\"]\n",
    "                        \n",
    "                        # 1. 先添加精确值（选择率合适的）\n",
    "                        value_counts = pd.to_numeric(df[attr], errors='coerce').value_counts().dropna()\n",
    "                        for value, count in value_counts.items():\n",
    "                            if pd.notna(value) and min_rows <= count <= max_rows:\n",
    "                                if attr in integer_attrs:\n",
    "                                    try:\n",
    "                                        value = int(float(value))\n",
    "                                    except:\n",
    "                                        continue\n",
    "                                values_list.append({\n",
    "                                    'value': value,\n",
    "                                    'count': count,\n",
    "                                    'selectivity': count / total_rows\n",
    "                                })\n",
    "                        \n",
    "                        # 2. 添加范围查询（基于分位数）\n",
    "                        quantiles = [0.2, 0.4, 0.6, 0.8]\n",
    "                        for q in quantiles:\n",
    "                            threshold = numeric_values.quantile(q)\n",
    "                            if attr in integer_attrs:\n",
    "                                threshold = int(threshold)\n",
    "                            \n",
    "                            try:\n",
    "                                # 确保对比的是纯数值列，避免类型错误\n",
    "                                clean_numeric = pd.to_numeric(df[attr], errors='coerce').dropna()\n",
    "                                \n",
    "                                # >= threshold\n",
    "                                ge_count = (clean_numeric >= threshold).sum()\n",
    "                                if min_rows <= ge_count <= max_rows:\n",
    "                                    values_list.append({\n",
    "                                        'value': threshold,\n",
    "                                        'operator': '>=',\n",
    "                                        'count': ge_count,\n",
    "                                        'selectivity': ge_count / total_rows\n",
    "                                    })\n",
    "                                \n",
    "                                # <= threshold  \n",
    "                                le_count = (clean_numeric <= threshold).sum()\n",
    "                                if min_rows <= le_count <= max_rows:\n",
    "                                    values_list.append({\n",
    "                                        'value': threshold,\n",
    "                                        'operator': '<=',\n",
    "                                        'count': le_count,\n",
    "                                        'selectivity': le_count / total_rows\n",
    "                                    })\n",
    "                            except Exception as threshold_error:\n",
    "                                print(f\"    跳过阈值 {threshold}: {threshold_error}\")\n",
    "                                continue\n",
    "                        \n",
    "                        # 如果没有合适的值，使用默认值\n",
    "                        if not values_list:\n",
    "                            default_values = [0, 1, 5, 10] if attr in integer_attrs else [0.0, 1.0, 5.0, 10.0]\n",
    "                            for val in default_values:\n",
    "                                try:\n",
    "                                    # 检查这些默认值的实际效果，使用清洁的数值列\n",
    "                                    clean_numeric = pd.to_numeric(df[attr], errors='coerce').dropna()\n",
    "                                    ge_count = (clean_numeric >= val).sum()\n",
    "                                    if ge_count >= min_rows:\n",
    "                                        values_list.append({\n",
    "                                            'value': val,\n",
    "                                            'operator': '>=',\n",
    "                                            'count': ge_count,\n",
    "                                            'selectivity': ge_count / total_rows\n",
    "                                        })\n",
    "                                        break\n",
    "                                except Exception as default_error:\n",
    "                                    print(f\"    默认值 {val} 处理失败: {default_error}\")\n",
    "                                    continue\n",
    "                        else:\n",
    "                            # 无法转换为数值，当作文本处理\n",
    "                            values_list = []\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"处理数值属性 {table_name}.{attr} 时出错: {e}\")\n",
    "                    print(f\"    数据样本: {non_null_values.head().tolist()}\")\n",
    "                    values_list = []\n",
    "            \n",
    "            # 处理非数值属性\n",
    "            if not values_list:  # 如果是非数值属性，或数值属性处理失败\n",
    "                if attr in multi_value_attributes_list:\n",
    "                    # 处理多值属性\n",
    "                    all_values = []\n",
    "                    for cell in non_null_values:\n",
    "                        cell_str = str(cell)\n",
    "                        if '||' in cell_str:\n",
    "                            split_values = [v.strip() for v in cell_str.split('||') if v.strip()]\n",
    "                            all_values.extend(split_values)\n",
    "                        elif ',' in cell_str:\n",
    "                            split_values = [v.strip() for v in cell_str.split(',') if v.strip()]\n",
    "                            all_values.extend(split_values)\n",
    "                        else:\n",
    "                            all_values.append(cell_str.strip())\n",
    "                    \n",
    "                    # 统计每个拆分值的出现次数\n",
    "                    from collections import Counter\n",
    "                    value_counts = Counter(all_values)\n",
    "                    \n",
    "                    for value, count in value_counts.items():\n",
    "                        if min_rows <= count <= max_rows:\n",
    "                            values_list.append({\n",
    "                                'value': value,\n",
    "                                'count': count,\n",
    "                                'selectivity': count / total_rows\n",
    "                            })\n",
    "                else:\n",
    "                    # 普通文本属性\n",
    "                    value_counts = df[attr].value_counts()\n",
    "                    for value, count in value_counts.items():\n",
    "                        if pd.notna(value) and min_rows <= count <= max_rows:\n",
    "                            values_list.append({\n",
    "                                'value': value,\n",
    "                                'count': count,\n",
    "                                'selectivity': count / total_rows\n",
    "                            })\n",
    "            \n",
    "            # 选择多样化的值（按selectivity排序后均匀选择）\n",
    "            if values_list:\n",
    "                values_list.sort(key=lambda x: x['selectivity'])\n",
    "                selected = []\n",
    "                step = max(1, len(values_list) // 10)  # 最多选10个值\n",
    "                for i in range(0, len(values_list), step):\n",
    "                    selected.append(values_list[i])\n",
    "                    if len(selected) >= 12:\n",
    "                        break\n",
    "                \n",
    "                attr_value_dict[table_name][attr] = selected\n",
    "                print(f\"  {table_name}.{attr}: 选择了 {len(selected)} 个值，selectivity范围 \"\n",
    "                      f\"{min(v['selectivity'] for v in selected):.3f}-{max(v['selectivity'] for v in selected):.3f}\")\n",
    "    \n",
    "    return attr_value_dict\n",
    "\n",
    "# 使用改进的函数获取属性值\n",
    "attr_value_dict = get_sample_values_by_selectivity(dataframes, min_rows=min_rows)\n",
    "\n",
    "print(\"\\n属性值示例:\")\n",
    "for table_name, table_values in attr_value_dict.items():\n",
    "    print(f\"\\n{table_name}表:\")\n",
    "    for attr, values in list(table_values.items())[:2]:  # 只显示前2个属性\n",
    "        if values:\n",
    "            # 显示前3个值的详细信息\n",
    "            sample_values = values[:3]\n",
    "            for i, v in enumerate(sample_values):\n",
    "                if isinstance(v, dict):\n",
    "                    op_info = f\" {v.get('operator', '==')}\" if 'operator' in v else \" ==\"\n",
    "                    print(f\"    {attr}[{i}]: {v['value']}{op_info} -> {v['count']}行 (选择率:{v['selectivity']:.3f})\")\n",
    "                else:\n",
    "                    print(f\"    {attr}[{i}]: {v}\")\n",
    "            if len(values) > 3:\n",
    "                print(f\"    ... 还有 {len(values)-3} 个值\")\n",
    "        else:\n",
    "            print(f\"  {attr}: 无有效值\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 枚举所有可能的Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修复build_filter_dict中的条件字符串生成\n",
    "\n",
    "def build_filter_dict_fixed(dataframes, attr_value_dict):\n",
    "    filter_dict = {}\n",
    "    \n",
    "    for table_name, df in tqdm(dataframes.items(), desc=\"处理表\"):\n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "        filter_dict[table_name] = {}\n",
    "        \n",
    "        for attr in tqdm(table_attributes[table_name].keys(), desc=f\"处理{table_name}属性\", leave=False):\n",
    "            if attr not in df.columns or attr not in attr_value_dict[table_name]:\n",
    "                continue\n",
    "                \n",
    "            condition_dict = {}\n",
    "            \n",
    "            for value_info in attr_value_dict[table_name][attr]:\n",
    "                try:\n",
    "                    # 提取实际值\n",
    "                    if isinstance(value_info, dict) and 'value' in value_info:\n",
    "                        actual_value = value_info['value']\n",
    "                        operator = value_info.get('operator', '==')\n",
    "                    else:\n",
    "                        actual_value = value_info\n",
    "                        operator = '=='\n",
    "                    \n",
    "                    # 生成正确的条件字符串\n",
    "                    if operator == '>=':\n",
    "                        condition_str = f\">={actual_value}\"\n",
    "                        mask = pd.to_numeric(df[attr], errors='coerce') >= actual_value\n",
    "                    elif operator == '<=':\n",
    "                        condition_str = f\"<={actual_value}\"\n",
    "                        mask = pd.to_numeric(df[attr], errors='coerce') <= actual_value\n",
    "                    elif operator == '>':\n",
    "                        condition_str = f\">{actual_value}\"\n",
    "                        mask = pd.to_numeric(df[attr], errors='coerce') > actual_value\n",
    "                    elif operator == '<':\n",
    "                        condition_str = f\"<{actual_value}\"\n",
    "                        mask = pd.to_numeric(df[attr], errors='coerce') < actual_value\n",
    "                    else:  # operator == '=='\n",
    "                        if attr in numerical_attr_list:\n",
    "                            condition_str = f\"=={actual_value}\"\n",
    "                            mask = pd.to_numeric(df[attr], errors='coerce') == actual_value\n",
    "                        else:\n",
    "                            condition_str = f\"=='{actual_value}'\"  # 文本值加引号\n",
    "                            mask = df[attr] == actual_value\n",
    "                    \n",
    "                    # 获取满足条件的行索引\n",
    "                    result_indices = df[mask.fillna(False)].index.tolist()\n",
    "                    \n",
    "                    if len(result_indices) >= min_rows:\n",
    "                        condition_dict[condition_str] = result_indices\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"处理条件 {table_name}.{attr} = {value_info} 时出错: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "            if condition_dict:\n",
    "                filter_dict[table_name][attr] = condition_dict\n",
    "    \n",
    "    return filter_dict\n",
    "\n",
    "# 修复WHERE条件组合中的表达式生成\n",
    "# 1. 修复WHERE条件生成 - 在build_where_combinations中直接生成正确格式\n",
    "\n",
    "def build_where_combinations_simple_fix(filter_dict, max_combinations=1200):\n",
    "    all_filters = []\n",
    "    \n",
    "    for table_name, table_filters in filter_dict.items():\n",
    "        for attr, conditions in table_filters.items():\n",
    "            for cond_str, indices in conditions.items():\n",
    "                if len(indices) >= min_rows:\n",
    "                    # 直接生成最终的WHERE表达式，提取实际值\n",
    "                    if '==' in cond_str:\n",
    "                        value = cond_str.split('==')[1]\n",
    "                        # 去掉引号并检查是否为空\n",
    "                        if value.startswith(\"'\") and value.endswith(\"'\"):\n",
    "                            actual_value = value[1:-1].strip()\n",
    "                            if not actual_value or actual_value == ' ':  # 跳过空值\n",
    "                                continue\n",
    "                            where_expr = f\"{attr} = '{actual_value}'\"\n",
    "                        else:\n",
    "                            try:\n",
    "                                actual_value = float(value) if '.' in value else int(value)\n",
    "                                where_expr = f\"{attr} = {actual_value}\"\n",
    "                            except:\n",
    "                                continue\n",
    "                    elif '>=' in cond_str:\n",
    "                        value = cond_str.split('>=')[1]\n",
    "                        try:\n",
    "                            actual_value = float(value) if '.' in value else int(value)\n",
    "                            where_expr = f\"{attr} >= {actual_value}\"\n",
    "                        except:\n",
    "                            continue\n",
    "                    elif '<=' in cond_str:\n",
    "                        value = cond_str.split('<=')[1]\n",
    "                        try:\n",
    "                            actual_value = float(value) if '.' in value else int(value)\n",
    "                            where_expr = f\"{attr} <= {actual_value}\"\n",
    "                        except:\n",
    "                            continue\n",
    "                    elif '>' in cond_str:\n",
    "                        value = cond_str.split('>')[1]\n",
    "                        try:\n",
    "                            actual_value = float(value) if '.' in value else int(value)\n",
    "                            where_expr = f\"{attr} > {actual_value}\"\n",
    "                        except:\n",
    "                            continue\n",
    "                    elif '<' in cond_str:\n",
    "                        value = cond_str.split('<')[1]\n",
    "                        try:\n",
    "                            actual_value = float(value) if '.' in value else int(value)\n",
    "                            where_expr = f\"{attr} < {actual_value}\"\n",
    "                        except:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    all_filters.append((table_name, attr, where_expr, set(indices)))\n",
    "    \n",
    "    # 组合逻辑保持不变\n",
    "    valid_where = []\n",
    "    seen_expressions = set()\n",
    "    \n",
    "    sampled_filters = balanced_sample(all_filters, sample_size=80, random_seed=42)\n",
    "    \n",
    "    for n in tqdm(range(1, 6), desc=\"生成Filter组合\"):\n",
    "        combinations = list(itertools.combinations(sampled_filters, n))\n",
    "        random.shuffle(combinations)\n",
    "        \n",
    "        if n == 1:\n",
    "            max_combos_this_round = int(max_combinations * 2 / 10)\n",
    "        elif n == 2:\n",
    "            max_combos_this_round = int(max_combinations * 3 / 10)\n",
    "        elif n == 3:\n",
    "            max_combos_this_round = int(max_combinations * 3 / 10)\n",
    "        elif n == 4:\n",
    "            max_combos_this_round = int(max_combinations * 1 / 10)\n",
    "        elif n == 5:\n",
    "            max_combos_this_round = int(max_combinations * 1 / 10)\n",
    "        else:\n",
    "            max_combos_this_round = 50\n",
    "            \n",
    "        combo_count = 0\n",
    "        for combo in tqdm(combinations, desc=f\"{n}个Filter组合\", leave=False):\n",
    "            if combo_count >= max_combos_this_round:\n",
    "                break\n",
    "                \n",
    "            for op in ['AND', 'OR']:\n",
    "                if n == 1:\n",
    "                    where_clause = combo[0][2]  # 已经是正确格式的where_expr\n",
    "                    result_indices = combo[0][3]\n",
    "                    tables_involved = [combo[0][0]]\n",
    "                else:\n",
    "                    where_expressions = [item[2] for item in combo]  # 已经是正确格式\n",
    "                    where_clause = f\" {op} \".join(where_expressions)\n",
    "                    \n",
    "                    combo_tables = [item[0] for item in combo]\n",
    "                    if len(set(combo_tables)) == 1:\n",
    "                        if op == 'AND':\n",
    "                            result_indices = set.intersection(*[item[3] for item in combo])\n",
    "                        else:\n",
    "                            result_indices = set.union(*[item[3] for item in combo])\n",
    "                    else:\n",
    "                        if op == 'AND':\n",
    "                            intersection = set.intersection(*[item[3] for item in combo])\n",
    "                            if len(intersection) >= min_rows:\n",
    "                                result_indices = intersection\n",
    "                            else:\n",
    "                                result_indices = max([item[3] for item in combo], key=len)\n",
    "                        else:\n",
    "                            result_indices = set.union(*[item[3] for item in combo])\n",
    "                    \n",
    "                    tables_involved = list(set(combo_tables))\n",
    "                \n",
    "                min_rows_required = min_rows if n <= 2 else max(1, min_rows // 2)\n",
    "                \n",
    "                if len(result_indices) >= min_rows_required and where_clause not in seen_expressions:\n",
    "                    seen_expressions.add(where_clause)\n",
    "                    \n",
    "                    query_dict = {\n",
    "                        \"WHERE Indices\": list(result_indices),\n",
    "                        \"WHERE Total Rows\": len(result_indices),\n",
    "                        \"WHERE\": where_clause,  # 现在这里存储的是正确格式的条件\n",
    "                        \"Tables\": tables_involved,\n",
    "                        \"Combination\": [[item[0], item[1], item[2]] for item in combo],\n",
    "                        \"Operator\": op if n > 1 else \"NONE\",\n",
    "                        \"Filter Count\": n\n",
    "                    }\n",
    "                    valid_where.append(query_dict)\n",
    "            \n",
    "            combo_count += 1\n",
    "    \n",
    "    return valid_where\n",
    "\n",
    "def filter_empty_values(attr_value_dict):\n",
    "    \"\"\"\n",
    "    过滤掉空值和无效值\n",
    "    \"\"\"\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    for table_name, table_attrs in attr_value_dict.items():\n",
    "        filtered_dict[table_name] = {}\n",
    "        \n",
    "        for attr, values in table_attrs.items():\n",
    "            filtered_values = []\n",
    "            \n",
    "            for value_info in values:\n",
    "                if isinstance(value_info, dict) and 'value' in value_info:\n",
    "                    actual_value = value_info['value']\n",
    "                    # 跳过空值\n",
    "                    if isinstance(actual_value, str):\n",
    "                        if actual_value.strip() == '' or actual_value.strip() == ' ':\n",
    "                            continue\n",
    "                    filtered_values.append(value_info)\n",
    "                else:\n",
    "                    # 直接值\n",
    "                    if isinstance(value_info, str):\n",
    "                        if value_info.strip() == '' or value_info.strip() == ' ':\n",
    "                            continue\n",
    "                    filtered_values.append(value_info)\n",
    "            \n",
    "            if filtered_values:\n",
    "                filtered_dict[table_name][attr] = filtered_values\n",
    "    \n",
    "    return filtered_dict\n",
    "\n",
    "# 使用修复\n",
    "print(\"过滤空值...\")\n",
    "attr_value_dict = filter_empty_values(attr_value_dict)\n",
    "\n",
    "print(\"重新构建filter_dict...\")\n",
    "filter_dict = build_filter_dict_fixed(dataframes, attr_value_dict)\n",
    "\n",
    "print(\"生成WHERE条件...\")\n",
    "valid_where = build_where_combinations_simple_fix(filter_dict, max_combinations=2000)\n",
    "\n",
    "print(f\"\\n修复后的WHERE条件示例:\")\n",
    "for i, where_dict in enumerate(valid_where[:3]):\n",
    "    print(f\"{i+1}. {where_dict['WHERE']}\")\n",
    "    print(f\"   -> {where_dict['WHERE Total Rows']}行\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建WHERE条件组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义SCHEMA创建函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 定义SCHEMA创建函数\n",
    "\n",
    "def create_schema(attr_desc_dict, query_attr_list):\n",
    "    schema = {}\n",
    "    for key in query_attr_list:\n",
    "        if key in non_numerical_attr_list:\n",
    "            schema[key] = [\"VARCHAR(255)\", attr_desc_dict.get(key, \"\")]\n",
    "        elif key in numerical_attr_list:\n",
    "            schema[key] = [\"FLOAT\", attr_desc_dict.get(key, \"\")]\n",
    "        else:\n",
    "            schema[key] = [\"VARCHAR(255)\", attr_desc_dict.get(key, \"\")]\n",
    "    return schema\n",
    "\n",
    "def create_multi_table_schema(tables, selected_attrs):\n",
    "    schema = {}\n",
    "    \n",
    "    for table, attr in selected_attrs:\n",
    "        column_name = f\"{table}.{attr}\"\n",
    "        \n",
    "        if attr in numerical_attr_list:\n",
    "            schema[column_name] = [\"FLOAT\", f\"{table} table {attr} field\"]\n",
    "        else:\n",
    "            schema[column_name] = [\"VARCHAR(255)\", f\"{table} table {attr} field\"]\n",
    "    \n",
    "    return schema\n",
    "\n",
    "# 通用的WHERE条件选择函数\n",
    "def select_where_by_ratio(valid_where, total_needed, single_table_only=True, multi_table_ratio=0.3):\n",
    "    \"\"\"\n",
    "    按比例选择WHERE条件\n",
    "    multi_table_ratio: 多filter的比例 (默认30%单filter, 70%多filter)\n",
    "    \"\"\"\n",
    "    if single_table_only:\n",
    "        single_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) == 1 and len(w[\"Tables\"]) == 1]\n",
    "        multi_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) > 1 and len(w[\"Tables\"]) == 1]\n",
    "    else:\n",
    "        single_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) == 1]\n",
    "        multi_filter = [w for w in valid_where if w.get(\"Filter Count\", 1) > 1]\n",
    "    \n",
    "    single_count = int(total_needed * (1 - multi_table_ratio))\n",
    "    multi_count = total_needed - single_count\n",
    "    \n",
    "    selected = multi_filter[:multi_count] + single_filter[:single_count]\n",
    "    return selected[:total_needed]\n",
    "\n",
    "def extract_attrs_from_where(where_clause):\n",
    "    \"\"\"从WHERE子句中提取属性名\"\"\"\n",
    "    import re\n",
    "    if not where_clause:\n",
    "        return []\n",
    "    attr_matches = re.findall(r'(\\w+)\\s*[><=!]', where_clause)\n",
    "    return attr_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM（单表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM（单表）\n",
    "\n",
    "def generate_select_from_queries(dataframes):\n",
    "    \"\"\"\n",
    "    生成简单的SELECT FROM查询（单表，无WHERE条件）\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # 为每个表生成查询\n",
    "    table_names = list(dataframes.keys())\n",
    "    if len(table_names) == 0:\n",
    "        print(\"警告：没有加载到任何表数据\")\n",
    "        return queries\n",
    "        \n",
    "    queries_per_table = sample_sf // len(table_names)\n",
    "    remainder = sample_sf % len(table_names)\n",
    "    \n",
    "    for i, table_name in enumerate(tqdm(table_names, desc=\"生成SF查询\")):\n",
    "        if dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        table_query_count = queries_per_table + (1 if i < remainder else 0)\n",
    "        \n",
    "        for _ in range(table_query_count):\n",
    "            available_attrs = list(table_attributes[table_name].keys())\n",
    "            if not available_attrs:\n",
    "                continue\n",
    "                \n",
    "            # 随机选择属性数量（1到max_select之间）\n",
    "            num_attrs = random.randint(1, min(max_select, len(available_attrs)))\n",
    "            selected_attrs = random.sample(available_attrs, num_attrs)\n",
    "            \n",
    "            # 计算表的总行数\n",
    "            total_rows = len(dataframes[table_name])\n",
    "            \n",
    "            query_dict = {\n",
    "                \"Type\": \"SF\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"WHERE Indices\": list(range(total_rows)),  # 所有行的索引\n",
    "                \"WHERE Total Rows\": total_rows,  # 表的总行数\n",
    "                \"WHERE\": \"\",  # 无WHERE条件\n",
    "                \"Tables\": [table_name],\n",
    "                \"Combination\": [],  # 无filter组合\n",
    "                \"Operator\": \"NONE\",\n",
    "                \"Filter Count\": 0,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, selected_attrs)\n",
    "            }\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sf_queries = generate_select_from_queries(dataframes)\n",
    "print(f\"生成SF查询: {len(sf_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM JOIN查询（多表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM JOIN查询（多表）\n",
    "\n",
    "def generate_select_from_join_queries(dataframes):\n",
    "    \"\"\"\n",
    "    生成SELECT FROM JOIN查询（多表，无WHERE条件）\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # 定义可能的JOIN组合 - 基于实际的JOIN关系\n",
    "    join_combinations = [\n",
    "        ['team', 'city'],           # team-city \n",
    "        ['owner', 'team'],          # owner-team\n",
    "        ['player', 'team'],         # player-team\n",
    "        ['team', 'city', 'owner'],  # team-city-owner\n",
    "        ['team', 'player', 'owner'] # team-player-owner\n",
    "    ]\n",
    "    \n",
    "    # 过滤掉不存在的表\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    if not valid_join_combinations:\n",
    "        print(\"警告：没有有效的JOIN组合\")\n",
    "        return queries\n",
    "    \n",
    "    # 为每种JOIN组合生成查询\n",
    "    queries_per_combo = sample_sfj // len(valid_join_combinations)\n",
    "    remainder = sample_sfj % len(valid_join_combinations)\n",
    "    \n",
    "    for i, join_combo in enumerate(tqdm(valid_join_combinations, desc=\"生成SFJ查询\")):\n",
    "        combo_query_count = queries_per_combo + (1 if i < remainder else 0)\n",
    "        \n",
    "        for _ in range(combo_query_count):\n",
    "            # 从每个表中选择属性\n",
    "            available_attrs = []\n",
    "            for table in join_combo:\n",
    "                # 每个表最多选择3个属性，避免SELECT子句过长\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:4]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "            \n",
    "            if not available_attrs:\n",
    "                continue\n",
    "                \n",
    "            # 随机选择属性数量（2到max_select之间）\n",
    "            num_attrs = random.randint(2, min(max_select, len(available_attrs)))\n",
    "            selected_attrs = random.sample(available_attrs, num_attrs)\n",
    "            select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "            \n",
    "            # 估算JOIN结果行数：使用参与表中行数最小的表作为估算\n",
    "            estimated_rows = min(len(dataframes[table]) for table in join_combo)\n",
    "            \n",
    "            query_dict = {\n",
    "                \"Type\": \"SFJ\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"WHERE Indices\": [],  # JOIN查询的具体索引需要执行才能确定\n",
    "                \"WHERE Total Rows\": estimated_rows,  # 使用估算的行数\n",
    "                \"WHERE\": \"\",  # 无WHERE条件\n",
    "                \"Tables\": join_combo,\n",
    "                \"Combination\": [],  # 无filter组合\n",
    "                \"Operator\": \"NONE\", \n",
    "                \"Filter Count\": 0,\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "            }\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sfj_queries = generate_select_from_join_queries(dataframes)\n",
    "print(f\"生成SFJ查询: {len(sfj_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE查询（单表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM WHERE查询（单表）\n",
    "\n",
    "def generate_select_from_where_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    \n",
    "    selected_where = select_where_by_ratio(valid_where, sample_sfw, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in tqdm(selected_where, desc=\"生成SFW查询\"):\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        available_attrs = list(table_attributes[table_name].keys())[:8]\n",
    "        if not available_attrs:\n",
    "            continue\n",
    "            \n",
    "        selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "        \n",
    "        # 修复：从WHERE字符串中提取属性，而不是从Combination\n",
    "        query_attr_list = selected_attrs.copy()\n",
    "        where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "        for attr in where_attrs:\n",
    "            if attr not in query_attr_list:\n",
    "                query_attr_list.append(attr)\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFW\",\n",
    "            \"SELECT\": selected_attrs,\n",
    "            \"FROM\": [table_name],\n",
    "            \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "sfw_queries = generate_select_from_where_queries(valid_where, dataframes)\n",
    "print(f\"生成SFW查询: {len(sfw_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建多表JOIN查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建多表JOIN查询\n",
    "\n",
    "def generate_join_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    \n",
    "    # 按比例选择WHERE条件\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    # 多表WHERE条件的JOIN查询\n",
    "    for where_dict in tqdm(multi_table_where, desc=\"生成多表JOIN查询\"):\n",
    "        tables_involved = where_dict[\"Tables\"] if len(where_dict[\"Tables\"]) > 1 else ['team', 'city']\n",
    "        \n",
    "        # 检查表是否存在\n",
    "        if not all(table in dataframes and not dataframes[table].empty for table in tables_involved):\n",
    "            continue\n",
    "            \n",
    "        available_attrs = []\n",
    "        for table in tables_involved:\n",
    "            table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "            available_attrs.extend(table_attrs)\n",
    "        \n",
    "        if not available_attrs:\n",
    "            continue\n",
    "            \n",
    "        selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "        select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFWJ\",\n",
    "            \"SELECT\": select_clause,\n",
    "            \"FROM\": tables_involved,\n",
    "            \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "            \"SCHEMA\": create_multi_table_schema(tables_involved, selected_attrs)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    # 单表WHERE条件应用到JOIN查询\n",
    "    join_combinations = [['team', 'city'], ['owner', 'team'], ['player', 'team']]\n",
    "    \n",
    "    # 过滤有效的JOIN组合\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    for where_dict in tqdm(single_table_for_join[:8], desc=\"生成单表->JOIN查询\", leave=False):\n",
    "        for join_combo in valid_join_combinations[:2]:\n",
    "            available_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "            \n",
    "            if not available_attrs:\n",
    "                continue\n",
    "                \n",
    "            selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "            select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWJ\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "join_queries = generate_join_queries(valid_where, dataframes)\n",
    "print(f\"生成JOIN查询: {len(join_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE TOP-K查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM WHERE TOP-K查询\n",
    "\n",
    "def generate_topk_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    order_options = ['ASC', 'DESC']\n",
    "    \n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwt, single_table_only=True, multi_table_ratio=0.6)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        available_attrs = list(table_attributes[table_name].keys())\n",
    "        numerical_attrs = [attr for attr in available_attrs if attr in numerical_attr_list]\n",
    "        \n",
    "        if numerical_attrs:\n",
    "            selected_attrs = random.sample(available_attrs[:8], min(max_select, len(available_attrs[:8])))\n",
    "            order_column = random.choice(numerical_attrs)\n",
    "            order_type = random.choice(order_options)\n",
    "            limit_value = random.choice(limit_list)\n",
    "            \n",
    "            query_attr_list = selected_attrs + [order_column]\n",
    "            where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "            for attr in where_attrs:\n",
    "                if attr not in query_attr_list:\n",
    "                    query_attr_list.append(attr)\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWT\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"ORDER BY\": [order_column, order_type],\n",
    "                \"LIMIT\": limit_value,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN TOP-K查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwtj//2, single_table_only=False, multi_table_ratio=0.7)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwtj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['team', 'city'], ['owner', 'team'], ['player', 'team']]\n",
    "    \n",
    "    # 过滤有效的JOIN组合\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:8]:\n",
    "        for join_combo in valid_join_combinations[:2]:\n",
    "            available_attrs = []\n",
    "            numerical_join_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                available_attrs.extend(table_attrs)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in table_attributes[table].keys() \n",
    "                                 if attr in numerical_attr_list]\n",
    "                numerical_join_attrs.extend(table_numerical)\n",
    "            \n",
    "            if numerical_join_attrs and available_attrs:\n",
    "                selected_attrs = random.sample(available_attrs, min(max_select, len(available_attrs)))\n",
    "                select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "                \n",
    "                order_table, order_attr = random.choice(numerical_join_attrs)\n",
    "                order_column = f\"{order_table}.{order_attr}\"\n",
    "                order_type = random.choice(order_options)\n",
    "                limit_value = random.choice(limit_list)\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWTJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"ORDER BY\": [order_column, order_type],\n",
    "                    \"LIMIT\": limit_value,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "topk_queries = generate_topk_queries(valid_where, dataframes)\n",
    "print(f\"生成TOP-K查询: {len(topk_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY查询\n",
    "\n",
    "def generate_groupby_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    \n",
    "    # 按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwg, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            selected_attrs = random.sample(list(table_attributes[table_name].keys())[:8], \n",
    "                                         min(max_select, len(list(table_attributes[table_name].keys())[:8])))\n",
    "            \n",
    "            if groupby_columns[0] not in selected_attrs:\n",
    "                selected_attrs = groupby_columns + selected_attrs[:max_select-1]\n",
    "            \n",
    "            query_attr_list = selected_attrs.copy()\n",
    "            where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "            for attr in where_attrs:\n",
    "                if attr not in query_attr_list:\n",
    "                    query_attr_list.append(attr)\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWG\",\n",
    "                \"SELECT\": selected_attrs,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN GROUP BY查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwgj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwgj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['team', 'city'], ['owner', 'team']]\n",
    "    \n",
    "    # 过滤有效的JOIN组合\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:8]:\n",
    "        for join_combo in valid_join_combinations:\n",
    "            join_category_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                available_attrs = []\n",
    "                for table in join_combo:\n",
    "                    table_attrs = [(table, attr) for attr in list(table_attributes[table].keys())[:3]]\n",
    "                    available_attrs.extend(table_attrs)\n",
    "                \n",
    "                if not available_attrs:\n",
    "                    continue\n",
    "                    \n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                selected_attrs = random.sample(available_attrs, min(max_select-1, len(available_attrs)))\n",
    "                selected_attrs.append((groupby_table, groupby_attr))\n",
    "                select_clause = [f\"{table}.{attr}\" for table, attr in selected_attrs]\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWGJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "groupby_queries = generate_groupby_queries(valid_where, dataframes)\n",
    "print(f\"生成GROUP BY查询: {len(groupby_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE AGGREGATION查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 构建SELECT FROM WHERE AGGREGATION查询\n",
    "\n",
    "def generate_aggregation_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    \n",
    "    # 按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwa, single_table_only=True, multi_table_ratio=0.6)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if numerical_attrs:\n",
    "            agg_column = random.choice(numerical_attrs)\n",
    "            function = random.choice(aggregation_functions[1:])\n",
    "            numerical = True\n",
    "        else:\n",
    "            agg_column = \"*\"\n",
    "            function = 'COUNT'\n",
    "            numerical = False\n",
    "        \n",
    "        query_attr_list = [agg_column] if agg_column != \"*\" else []\n",
    "        where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "        for attr in where_attrs:\n",
    "            if attr not in query_attr_list:\n",
    "                query_attr_list.append(attr)\n",
    "        \n",
    "        query_dict = where_dict.copy()\n",
    "        query_dict.update({\n",
    "            \"Type\": \"SFWA\",\n",
    "            \"SELECT\": [f\"{function}({agg_column})\"],\n",
    "            \"FROM\": [table_name],\n",
    "            \"AGGREGATION\": [agg_column],\n",
    "            \"AGGREGATION Function\": function,\n",
    "            \"Numerical\": numerical,\n",
    "            \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "        })\n",
    "        \n",
    "        queries.append(query_dict)\n",
    "    \n",
    "    # JOIN AGGREGATION查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwaj//2, single_table_only=False, multi_table_ratio=0.7)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwaj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['team', 'city'], ['owner', 'team']]\n",
    "    \n",
    "    # 过滤有效的JOIN组合\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:8]:\n",
    "        for join_combo in valid_join_combinations:\n",
    "            join_numerical_attrs = []\n",
    "            for table in join_combo:\n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_numerical_attrs:\n",
    "                agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWAJ\",\n",
    "                \"SELECT\": [f\"{function}({agg_column})\"],\n",
    "                \"FROM\": join_combo,\n",
    "                \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"SCHEMA\": create_multi_table_schema(join_combo, [(agg_table, agg_attr)] if agg_column != \"*\" else [])\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "aggregation_queries = generate_aggregation_queries(valid_where, dataframes)\n",
    "print(f\"生成AGGREGATION查询: {len(aggregation_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY AGGREGATION查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_groupby_aggregation_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    \n",
    "    # 按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwga, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            \n",
    "            if numerical_attrs:\n",
    "                agg_column = random.choice(numerical_attrs)\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "            \n",
    "            select_clause = groupby_columns + [f\"{function}({agg_column})\"]\n",
    "            \n",
    "            query_attr_list = groupby_columns + ([agg_column] if agg_column != \"*\" else [])\n",
    "            where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "            for attr in where_attrs:\n",
    "                if attr not in query_attr_list:\n",
    "                    query_attr_list.append(attr)\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWGA\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    # JOIN GROUP BY AGGREGATION查询\n",
    "    multi_table_where = select_where_by_ratio(valid_where, sample_sfwgaj//2, single_table_only=False, multi_table_ratio=0.6)\n",
    "    single_table_for_join = select_where_by_ratio(valid_where, sample_sfwgaj//2, single_table_only=True, multi_table_ratio=0.8)\n",
    "    \n",
    "    join_combinations = [['team', 'city'], ['owner', 'team']]\n",
    "    \n",
    "    # 过滤有效的JOIN组合\n",
    "    valid_join_combinations = []\n",
    "    for combo in join_combinations:\n",
    "        if all(table in dataframes and not dataframes[table].empty for table in combo):\n",
    "            valid_join_combinations.append(combo)\n",
    "    \n",
    "    for where_dict in multi_table_where + single_table_for_join[:8]:\n",
    "        for join_combo in valid_join_combinations:\n",
    "            join_category_attrs = []\n",
    "            join_numerical_attrs = []\n",
    "            \n",
    "            for table in join_combo:\n",
    "                table_categories = [(table, attr) for attr in category_attr.get(table, [])]\n",
    "                join_category_attrs.extend(table_categories)\n",
    "                \n",
    "                table_numerical = [(table, attr) for attr in numerical_attr.get(table, [])]\n",
    "                join_numerical_attrs.extend(table_numerical)\n",
    "            \n",
    "            if join_category_attrs:\n",
    "                groupby_table, groupby_attr = random.choice(join_category_attrs)\n",
    "                groupby_column = f\"{groupby_table}.{groupby_attr}\"\n",
    "                \n",
    "                if join_numerical_attrs:\n",
    "                    agg_table, agg_attr = random.choice(join_numerical_attrs)\n",
    "                    agg_column = f\"{agg_table}.{agg_attr}\"\n",
    "                    function = random.choice(aggregation_functions[1:])\n",
    "                    numerical = True\n",
    "                    selected_attrs = [(groupby_table, groupby_attr), (agg_table, agg_attr)]\n",
    "                else:\n",
    "                    agg_column = \"*\"\n",
    "                    function = 'COUNT'\n",
    "                    numerical = False\n",
    "                    selected_attrs = [(groupby_table, groupby_attr)]\n",
    "                \n",
    "                select_clause = [groupby_column, f\"{function}({agg_column})\"]\n",
    "                \n",
    "                query_dict = where_dict.copy()\n",
    "                query_dict.update({\n",
    "                    \"Type\": \"SFWGAJ\",\n",
    "                    \"SELECT\": select_clause,\n",
    "                    \"FROM\": join_combo,\n",
    "                    \"JOIN_TYPE\": \"INNER JOIN\",\n",
    "                    \"GROUP BY\": [groupby_column],\n",
    "                    \"AGGREGATION\": [agg_column],\n",
    "                    \"AGGREGATION Function\": function,\n",
    "                    \"Numerical\": numerical,\n",
    "                    \"SCHEMA\": create_multi_table_schema(join_combo, selected_attrs)\n",
    "                })\n",
    "                \n",
    "                queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "groupby_aggregation_queries = generate_groupby_aggregation_queries(valid_where, dataframes)\n",
    "print(f\"生成GROUP BY AGGREGATION查询: {len(groupby_aggregation_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建SELECT FROM WHERE GROUP BY AGGREGATION TOP-K查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groupby_aggregation_topk_queries(valid_where, dataframes):\n",
    "    queries = []\n",
    "    aggregation_functions = ['COUNT', 'MAX', 'MIN', 'AVG', 'SUM']\n",
    "    order_options = ['ASC', 'DESC']\n",
    "    \n",
    "    # 按比例选择WHERE条件\n",
    "    single_table_where = select_where_by_ratio(valid_where, sample_sfwgat, single_table_only=True, multi_table_ratio=0.7)\n",
    "    \n",
    "    for where_dict in single_table_where:\n",
    "        table_name = where_dict[\"Tables\"][0]\n",
    "        \n",
    "        if table_name not in dataframes or dataframes[table_name].empty:\n",
    "            continue\n",
    "            \n",
    "        category_attrs = category_attr.get(table_name, [])\n",
    "        numerical_attrs = numerical_attr.get(table_name, [])\n",
    "        \n",
    "        if category_attrs:\n",
    "            groupby_columns = random.sample(category_attrs, 1)\n",
    "            \n",
    "            if numerical_attrs and random.random() > 0.5:\n",
    "                agg_column = random.choice(numerical_attrs)\n",
    "                function = random.choice(aggregation_functions[1:])\n",
    "                numerical = True\n",
    "                order_column = f\"{function}({agg_column})\"\n",
    "            else:\n",
    "                agg_column = \"*\"\n",
    "                function = 'COUNT'\n",
    "                numerical = False\n",
    "                order_column = f\"COUNT(*)\"\n",
    "            \n",
    "            order_type = random.choice(order_options)\n",
    "            limit_value = random.choice(limit_list)\n",
    "            \n",
    "            select_clause = groupby_columns + [f\"{function}({agg_column})\"]\n",
    "            \n",
    "            query_attr_list = groupby_columns + ([agg_column] if agg_column != \"*\" else [])\n",
    "            where_attrs = extract_attrs_from_where(where_dict.get(\"WHERE\", \"\"))\n",
    "            for attr in where_attrs:\n",
    "                if attr not in query_attr_list:\n",
    "                    query_attr_list.append(attr)\n",
    "            \n",
    "            query_dict = where_dict.copy()\n",
    "            query_dict.update({\n",
    "                \"Type\": \"SFWGAT\",\n",
    "                \"SELECT\": select_clause,\n",
    "                \"FROM\": [table_name],\n",
    "                \"GROUP BY\": groupby_columns,\n",
    "                \"AGGREGATION\": [agg_column],\n",
    "                \"AGGREGATION Function\": function,\n",
    "                \"Numerical\": numerical,\n",
    "                \"ORDER BY\": [order_column, order_type],\n",
    "                \"LIMIT\": limit_value,\n",
    "                \"SCHEMA\": create_schema(attr_desc_dict, query_attr_list)\n",
    "            })\n",
    "            \n",
    "            queries.append(query_dict)\n",
    "    \n",
    "    return queries\n",
    "\n",
    "groupby_aggregation_topk_queries = generate_groupby_aggregation_topk_queries(valid_where, dataframes)\n",
    "print(f\"生成GROUP BY AGGREGATION TOP-K查询: {len(groupby_aggregation_topk_queries)} 个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的SQL生成函数定义\n",
    "\n",
    "def generate_sql_query(query_dict):\n",
    "    \"\"\"\n",
    "    根据查询字典生成对应的SQL语句\n",
    "    \"\"\"\n",
    "    # 获取字段，提供默认值\n",
    "    tables_list = query_dict.get(\"FROM\", [\"nba_table\"])\n",
    "    select_fields = query_dict.get(\"SELECT\", [\"*\"])\n",
    "    \n",
    "    select_clause = \"SELECT \" + \", \".join(select_fields)\n",
    "    \n",
    "    if len(tables_list) == 1:\n",
    "        from_clause = f\"FROM {tables_list[0]}\"\n",
    "    else:\n",
    "        from_clause = f\"FROM {tables_list[0]}\"\n",
    "        \n",
    "        # 修复：使用正确的NBA业务JOIN关系\n",
    "        for i in range(1, len(tables_list)):\n",
    "            current_table = tables_list[i]\n",
    "            prev_table = tables_list[i-1]\n",
    "            \n",
    "            join_condition = None\n",
    "            \n",
    "            # owner -> team: team字段 = team_name字段\n",
    "            if (prev_table == \"owner\" and current_table == \"team\") or \\\n",
    "               (prev_table == \"team\" and current_table == \"owner\"):\n",
    "                join_condition = \"owner.team = team.team_name\"\n",
    "            \n",
    "            # team -> city: city字段 = city字段 (注意：实际数据中可能是location)\n",
    "            elif (prev_table == \"team\" and current_table == \"city\") or \\\n",
    "                 (prev_table == \"city\" and current_table == \"team\"):\n",
    "                join_condition = \"team.city = city.city\"\n",
    "            \n",
    "            # player -> team: team字段 = team_name字段\n",
    "            elif (prev_table == \"player\" and current_table == \"team\") or \\\n",
    "                 (prev_table == \"team\" and current_table == \"player\"):\n",
    "                join_condition = \"player.team = team.team_name\"\n",
    "            \n",
    "            # 三表JOIN的特殊处理\n",
    "            elif len(tables_list) == 3:\n",
    "                if \"owner\" in tables_list and \"team\" in tables_list and \"player\" in tables_list:\n",
    "                    if i == 2:  # 第三个表的JOIN\n",
    "                        if current_table == \"player\":\n",
    "                            join_condition = \"player.team = team.team_name\"\n",
    "                        elif current_table == \"owner\":\n",
    "                            join_condition = \"owner.team = team.team_name\"\n",
    "                elif \"team\" in tables_list and \"city\" in tables_list and \"player\" in tables_list:\n",
    "                    if i == 2:\n",
    "                        if current_table == \"city\":\n",
    "                            join_condition = \"team.city = city.city\"\n",
    "                        elif current_table == \"player\":\n",
    "                            join_condition = \"player.team = team.team_name\"\n",
    "            \n",
    "            if join_condition:\n",
    "                from_clause += f\"\\nINNER JOIN {current_table} ON {join_condition}\"\n",
    "            else:\n",
    "                print(f\"Warning: Using fallback join for {prev_table} -> {current_table}\")\n",
    "                # 备选方案：使用业务主键\n",
    "                from_clause += f\"\\nINNER JOIN {current_table} ON {tables_list[0]}.team_name = {current_table}.team\"\n",
    "    \n",
    "    sql_parts = [select_clause, from_clause]\n",
    "    \n",
    "    if query_dict.get(\"WHERE\"):\n",
    "        sql_parts.append(f\"WHERE {query_dict['WHERE']}\")\n",
    "    if query_dict.get(\"GROUP BY\"):\n",
    "        sql_parts.append(f\"GROUP BY {', '.join(query_dict['GROUP BY'])}\")\n",
    "    if query_dict.get(\"ORDER BY\"):\n",
    "        order_col, order_type = query_dict[\"ORDER BY\"]\n",
    "        sql_parts.append(f\"ORDER BY {order_col} {order_type}\")\n",
    "    if query_dict.get(\"LIMIT\"):\n",
    "        sql_parts.append(f\"LIMIT {query_dict['LIMIT']}\")\n",
    "    \n",
    "    return \"\\n\".join(sql_parts) + \";\"\n",
    "\n",
    "def generate_schema_sql(schema_dict, table_name=\"NBA_Data\"):\n",
    "    \"\"\"\n",
    "    根据SCHEMA字典生成建表SQL语句\n",
    "    \"\"\"\n",
    "    if not schema_dict:\n",
    "        return f\"CREATE TABLE {table_name} (id INTEGER PRIMARY KEY);\"\n",
    "    \n",
    "    create_table = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    columns = []\n",
    "    \n",
    "    for col_name, (data_type, description) in schema_dict.items():\n",
    "        comment = f\" COMMENT '{description}'\" if description else \"\"\n",
    "        columns.append(f\"    {col_name} {data_type}{comment}\")\n",
    "    \n",
    "    create_table += \",\\n\".join(columns)\n",
    "    create_table += \"\\n);\"\n",
    "    \n",
    "    return create_table\n",
    "\n",
    "def save_nba_queries_to_sql(output_dir=\"./sql_queries/\"):\n",
    "    \"\"\"\n",
    "    读取所有生成的查询，为每个查询生成对应的SQL语句并保存\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 收集所有查询\n",
    "    all_queries = []\n",
    "    query_vars = [\n",
    "        'sf_queries', 'sfj_queries', 'sfw_queries', 'join_queries', \n",
    "        'topk_queries', 'groupby_queries', 'aggregation_queries',\n",
    "        'groupby_aggregation_queries', 'groupby_aggregation_topk_queries'\n",
    "    ]\n",
    "    \n",
    "    for var_name in query_vars:\n",
    "        if var_name in globals() and globals()[var_name]:\n",
    "            all_queries.extend(globals()[var_name])\n",
    "    \n",
    "    if not all_queries:\n",
    "        print(\"没有找到查询数据\")\n",
    "        return\n",
    "    \n",
    "    # 按查询类型分组\n",
    "    queries_by_type = {}\n",
    "    for query in all_queries:\n",
    "        query_type = query.get('Type', 'Unknown')\n",
    "        if query_type not in queries_by_type:\n",
    "            queries_by_type[query_type] = []\n",
    "        queries_by_type[query_type].append(query)\n",
    "    \n",
    "    # 为每种类型生成SQL文件\n",
    "    for query_type, queries in queries_by_type.items():\n",
    "        \n",
    "        # 为每个查询生成SQL\n",
    "        for i, query in enumerate(queries):\n",
    "            # 确定表名\n",
    "            tables = query.get(\"FROM\", [\"nba_table\"])\n",
    "            if len(tables) == 1:\n",
    "                table_name = tables[0]\n",
    "            else:\n",
    "                table_name = \"NBA_Data\"  # 多表时使用通用名称\n",
    "            \n",
    "            # 生成建表SQL\n",
    "            schema_dict = query.get(\"SCHEMA\", {})\n",
    "            schema_sql = generate_schema_sql(schema_dict, table_name)\n",
    "            \n",
    "            # 生成查询SQL\n",
    "            query_sql = generate_sql_query(query)\n",
    "            \n",
    "            # 计算统计信息\n",
    "            select_count = len(query.get(\"SELECT\", []))\n",
    "            filter_count = len(query.get(\"Combination\", []))\n",
    "            \n",
    "            # 组合完整SQL\n",
    "            complete_sql = f\"-- Query {i+1} ({query['Type']})\\n\"\n",
    "            complete_sql += f\"-- Total Rows: {query.get('WHERE Total Rows', 'N/A')}\\n\"\n",
    "            complete_sql += f\"-- SELECT: {select_count}\\n\"\n",
    "            complete_sql += f\"-- FILTER: {filter_count}\\n\"\n",
    "            if len(query.get(\"FROM\", [])) > 1:\n",
    "                complete_sql += f\"-- TABLES: {', '.join(query['FROM'])}\\n\"\n",
    "            complete_sql += \"\\n\"\n",
    "            complete_sql += schema_sql + \"\\n\\n\"\n",
    "            complete_sql += query_sql + \"\\n\"\n",
    "            complete_sql += \"-\" * 50 + \"\\n\\n\"\n",
    "            \n",
    "            # 保存到查询对象中\n",
    "            query[\"SQL\"] = {\n",
    "                \"schema\": schema_sql,\n",
    "                \"query\": query_sql,\n",
    "                \"complete\": complete_sql\n",
    "            }\n",
    "        \n",
    "        # 保存SQL文件\n",
    "        sql_file = os.path.join(output_dir, f\"{query_type}.sql\")\n",
    "        with open(sql_file, 'w', encoding='utf-8') as f:\n",
    "            for query in queries:\n",
    "                f.write(query[\"SQL\"][\"complete\"])\n",
    "        \n",
    "        print(f\"已生成SQL文件: {sql_file} ({len(queries)} 个查询)\")\n",
    "\n",
    "# 执行保存\n",
    "print(\"开始生成NBA SQL文件...\")\n",
    "save_nba_queries_to_sql()\n",
    "print(\"SQL文件生成完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存所有查询结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NBA Join查询\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NBA Join查询生成器集成代码 - 完整修复版本\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# NBA业务场景模板定义 - 所有模板都包含player表\n",
    "NBA_TEMPLATES = [\n",
    "    # 单表模板 - 球员相关\n",
    "    {\"name\": \"nationality_analysis\", \"description\": \"特定国籍球员分析\", \n",
    "     \"filters\": [\"nationality\"], \"primary_table\": \"player\"},\n",
    "    {\"name\": \"age_performance\", \"description\": \"年龄与表现关系研究\", \n",
    "     \"filters\": [\"age\", \"nba_championships\"], \"primary_table\": \"player\"},\n",
    "    {\"name\": \"draft_analysis\", \"description\": \"选秀球员分析\", \n",
    "     \"filters\": [\"draft_year\", \"draft_pick\"], \"primary_table\": \"player\"},\n",
    "    {\"name\": \"champion_players\", \"description\": \"冠军球员研究\", \n",
    "     \"filters\": [\"nba_championships\"], \"primary_table\": \"player\"},\n",
    "    {\"name\": \"mvp_study\", \"description\": \"MVP球员研究\", \n",
    "     \"filters\": [\"mvp_awards\"], \"primary_table\": \"player\"},\n",
    "    \n",
    "    # 双表JOIN模板 - player + team\n",
    "    {\"name\": \"team_performance_players\", \"description\": \"球队表现与球员关系\", \n",
    "     \"filters\": [\"championship\", \"age\"], \"tables\": [\"player\", \"team\"]},\n",
    "    {\"name\": \"superstar_teams\", \"description\": \"巨星球员所在球队\", \n",
    "     \"filters\": [\"mvp_awards\", \"championship\"], \"tables\": [\"player\", \"team\"]},\n",
    "    \n",
    "    # 双表JOIN模板 - player + owner\n",
    "    {\"name\": \"nationality_ownership\", \"description\": \"球员国籍与老板关系\", \n",
    "     \"filters\": [\"nationality\", \"age\"], \"tables\": [\"player\", \"owner\"]},\n",
    "    \n",
    "    # 三表JOIN模板 - player + team + owner\n",
    "    {\"name\": \"player_team_owner_dynamics\", \"description\": \"球员-球队-老板动态分析\", \n",
    "     \"filters\": [\"age\", \"championship\", \"own_year\"], \n",
    "     \"tables\": [\"player\", \"team\", \"owner\"]},\n",
    "    {\"name\": \"mvp_ownership_success\", \"description\": \"MVP球员与老板成功关系\", \n",
    "     \"filters\": [\"mvp_awards\", \"founded_year\", \"nationality\"], \n",
    "     \"tables\": [\"player\", \"team\", \"owner\"]},\n",
    "]\n",
    "\n",
    "# 查询类型定义\n",
    "NBA_SINGLE_TYPES = [\"SF\", \"SFW\", \"SFWT\", \"SFWG\", \"SFWA\", \"SFWGA\", \"SFWGAT\"]\n",
    "NBA_JOIN_TYPES = [\"SFJ\", \"SFWJ\", \"SFWTJ\", \"SFWGJ\", \"SFWAJ\", \"SFWGAJ\", \"SFWGATJ\"]\n",
    "\n",
    "class NBASQLTemplateGenerator:\n",
    "    def __init__(self, dataframes, attr_value_dict, filter_dict, join_relationships):\n",
    "        self.dataframes = dataframes\n",
    "        self.attr_value_dict = attr_value_dict\n",
    "        self.filter_dict = filter_dict\n",
    "        \n",
    "        # 修复：正确定义NBA表之间的JOIN关系\n",
    "        self.join_relationships = {\n",
    "            (\"owner\", \"team\"): (\"team\", \"team_name\"),           # owner表的team字段 = team表的team_name字段\n",
    "            (\"team\", \"city\"): (\"city\", \"city\"),                 # team表的city字段 = city表的city字段\n",
    "            (\"player\", \"team\"): (\"team\", \"team_name\"),          # player表的team字段 = team表的team_name字段\n",
    "            # 间接关系（通过team表连接）\n",
    "            (\"owner\", \"player\"): \"via_team\",                    # owner -> team -> player\n",
    "            (\"player\", \"city\"): \"via_team\"                      # player -> team -> city\n",
    "        }\n",
    "        \n",
    "        self.min_rows = 1\n",
    "        \n",
    "        self.table_attr_mapping = {\n",
    "            \"city\": [\"city\", \"state_name\", \"population\", \"area\", \"gdp\"],\n",
    "            \"owner\": [\"name\", \"age\", \"nationality\", \"team\", \"own_year\"], \n",
    "            \"team\": [\"team_name\", \"founded_year\", \"city\", \"ownership\", \"championship\"],\n",
    "            \"player\": [\"name\", \"birth_date\", \"nationality\", \"age\", \"team\", \"position\", \n",
    "                      \"draft_pick\", \"draft_year\", \"college\", \"nba_championships\", \n",
    "                      \"mvp_awards\", \"olympic_gold_medals\", \"fiba_world_cup\"]\n",
    "        }\n",
    "    \n",
    "    def get_template_filter_value(self, table_name, attr, relaxation_level=0):\n",
    "        \"\"\"智能获取模板Filter值 - 直接生成条件，不验证结果\"\"\"\n",
    "        if (table_name not in self.attr_value_dict or \n",
    "            attr not in self.attr_value_dict[table_name]):\n",
    "            return None, None\n",
    "            \n",
    "        values = self.attr_value_dict[table_name][attr]\n",
    "        if not values:\n",
    "            return None, None\n",
    "        \n",
    "        # 从values中随机选择一个值\n",
    "        selected_value_info = random.choice(values)\n",
    "        \n",
    "        # 检查值的格式并提取实际值\n",
    "        if isinstance(selected_value_info, dict) and 'value' in selected_value_info:\n",
    "            actual_value = selected_value_info['value']\n",
    "            # 如果已经有预定义的操作符，可以直接使用\n",
    "            if 'operator' in selected_value_info:\n",
    "                operator = selected_value_info['operator']\n",
    "                return actual_value, f\"{table_name}.{attr} {operator} {actual_value}\"\n",
    "        else:\n",
    "            # 直接的值\n",
    "            actual_value = selected_value_info\n",
    "        \n",
    "        # 跳过空值\n",
    "        if isinstance(actual_value, str) and (actual_value.strip() == '' or actual_value.strip() == ' '):\n",
    "            return None, None\n",
    "        \n",
    "        # 数值属性处理\n",
    "        if attr in numerical_attr_list:\n",
    "            # 简化操作符选择\n",
    "            if relaxation_level == 0:\n",
    "                op = random.choice([\"==\", \">\", \">=\", \"<\", \"<=\"])\n",
    "            else:\n",
    "                op = random.choice([\">=\", \"<=\"])  # 范围查询\n",
    "            \n",
    "            return actual_value, f\"{table_name}.{attr} {op} {actual_value}\"\n",
    "        else:\n",
    "            # 文本属性处理\n",
    "            return actual_value, f\"{table_name}.{attr} = '{actual_value}'\"\n",
    "    \n",
    "    def apply_template_filters(self, template, max_relaxation=2):\n",
    "        \"\"\"应用模板Filter - 无论结果多少都生成查询\"\"\"\n",
    "        # 确定涉及的表\n",
    "        if \"primary_table\" in template:\n",
    "            tables_involved = [template[\"primary_table\"]]\n",
    "        elif \"tables\" in template:\n",
    "            tables_involved = template[\"tables\"]\n",
    "        else:\n",
    "            # 自动推断表\n",
    "            tables_involved = []\n",
    "            for filter_attr in template[\"filters\"]:\n",
    "                for table_name, attrs in self.table_attr_mapping.items():\n",
    "                    if filter_attr in attrs and table_name not in tables_involved:\n",
    "                        tables_involved.append(table_name)\n",
    "        \n",
    "        if not tables_involved:\n",
    "            return None, None, \"NO_VALID_TABLES\"\n",
    "        \n",
    "        # 尝试不同放宽级别，但无论结果多少都生成\n",
    "        for relaxation_level in range(max_relaxation + 1):\n",
    "            conditions = []\n",
    "            success = True\n",
    "            \n",
    "            # 尝试为每个filter生成条件\n",
    "            for filter_attr in template[\"filters\"]:\n",
    "                condition_found = False\n",
    "                for table_name in tables_involved:\n",
    "                    if filter_attr in self.table_attr_mapping.get(table_name, []):\n",
    "                        val, condition = self.get_template_filter_value(\n",
    "                            table_name, filter_attr, relaxation_level\n",
    "                        )\n",
    "                        if condition:\n",
    "                            conditions.append(condition)\n",
    "                            condition_found = True\n",
    "                            break\n",
    "                \n",
    "                if not condition_found:\n",
    "                    success = False\n",
    "                    break\n",
    "            \n",
    "            # 只要成功生成了条件就返回，不验证结果数量\n",
    "            if success and len(conditions) >= 1:\n",
    "                # 简单估算，不验证实际结果\n",
    "                estimated_rows = 1  # 假设至少有1行结果\n",
    "                return list(range(estimated_rows)), conditions, relaxation_level\n",
    "        \n",
    "        return None, None, \"FAILED_ALL_RELAXATION\"\n",
    "    \n",
    "    def generate_join_clause(self, tables):\n",
    "        \"\"\"生成正确的JOIN子句\"\"\"\n",
    "        if len(tables) <= 1:\n",
    "            return \"\"\n",
    "        \n",
    "        join_parts = []\n",
    "        \n",
    "        for i in range(1, len(tables)):\n",
    "            current_table = tables[i]\n",
    "            join_condition = None\n",
    "            \n",
    "            # 寻找当前表与之前任一表的JOIN关系\n",
    "            for prev_idx in range(i):\n",
    "                prev_table = tables[prev_idx]\n",
    "                \n",
    "                # 检查直接的JOIN关系\n",
    "                for (t1, t2), (key1, key2) in self.join_relationships.items():\n",
    "                    if isinstance((key1, key2), tuple):  # 直接关系\n",
    "                        if (prev_table == t1 and current_table == t2):\n",
    "                            join_condition = f\"{prev_table}.{key1} = {current_table}.{key2}\"\n",
    "                            break\n",
    "                        elif (prev_table == t2 and current_table == t1):\n",
    "                            join_condition = f\"{prev_table}.{key2} = {current_table}.{key1}\"\n",
    "                            break\n",
    "                \n",
    "                if join_condition:\n",
    "                    break\n",
    "            \n",
    "            # 如果没有找到直接关系，处理间接关系\n",
    "            if not join_condition:\n",
    "                # 三表JOIN的特殊处理\n",
    "                if len(tables) == 3 and \"team\" in tables:\n",
    "                    if current_table == \"player\" and \"team\" in tables[:i+1]:\n",
    "                        join_condition = \"player.team = team.team_name\"\n",
    "                    elif current_table == \"owner\" and \"team\" in tables[:i+1]:\n",
    "                        join_condition = \"owner.team = team.team_name\"\n",
    "                    elif current_table == \"city\" and \"team\" in tables[:i+1]:\n",
    "                        join_condition = \"team.city = city.city\"\n",
    "                    elif current_table == \"team\":\n",
    "                        if \"player\" in tables[:i]:\n",
    "                            join_condition = \"player.team = team.team_name\"\n",
    "                        elif \"owner\" in tables[:i]:\n",
    "                            join_condition = \"owner.team = team.team_name\"\n",
    "                        elif \"city\" in tables[:i]:\n",
    "                            join_condition = \"team.city = city.city\"\n",
    "            \n",
    "            if join_condition:\n",
    "                join_parts.append(f\"INNER JOIN {current_table} ON {join_condition}\")\n",
    "            else:\n",
    "                # 最后的备选方案\n",
    "                print(f\"Warning: Using fallback join for {current_table}\")\n",
    "                join_parts.append(f\"INNER JOIN {current_table} ON {tables[0]}.team_name = {current_table}.team\")\n",
    "        \n",
    "        return \"\\n\" + \"\\n\".join(join_parts) if join_parts else \"\"\n",
    "    \n",
    "    def create_multi_table_schema(self, tables):\n",
    "        \"\"\"创建多表Schema\"\"\"\n",
    "        schemas = []\n",
    "        for table in tables:\n",
    "            if table in self.dataframes:\n",
    "                attrs = self.table_attr_mapping.get(table, [])\n",
    "                schema_parts = [f\"    {table}_id INTEGER PRIMARY KEY\"]\n",
    "                \n",
    "                for attr in attrs:\n",
    "                    if attr in numerical_attr_list:\n",
    "                        schema_parts.append(f\"    {attr} FLOAT\")\n",
    "                    else:\n",
    "                        schema_parts.append(f\"    {attr} VARCHAR(255)\")\n",
    "                \n",
    "                schema = f\"CREATE TABLE {table} (\\n\"\n",
    "                schema += \",\\n\".join(schema_parts)\n",
    "                schema += \"\\n);\"\n",
    "                schemas.append(schema)\n",
    "        \n",
    "        return \"\\n\\n\".join(schemas)\n",
    "    \n",
    "    def generate_query_sql(self, template, query_type, query_id):\n",
    "        \"\"\"生成查询SQL - 总是生成查询，无论是否有结果\"\"\"\n",
    "        # 应用模板Filter\n",
    "        result = self.apply_template_filters(template)\n",
    "        \n",
    "        if result[2] in [\"FAILED_ALL_RELAXATION\", \"NO_VALID_TABLES\"]:\n",
    "            # 即使失败也生成基本查询\n",
    "            if \"primary_table\" in template:\n",
    "                tables = [template[\"primary_table\"]]\n",
    "            elif \"tables\" in template:\n",
    "                tables = template[\"tables\"]\n",
    "            else:\n",
    "                tables = [\"player\"]\n",
    "            \n",
    "            # 生成无WHERE条件的基本查询\n",
    "            conditions = []\n",
    "            relaxation_used = \"FAILED\"\n",
    "            \n",
    "            is_join = query_type.endswith('J')\n",
    "            header = f\"-- Query {query_id} - {query_type}\"\n",
    "            header += \" (JOIN)\" if is_join else \" (Single Table)\"\n",
    "            header += f\"\\n-- Template: {template['name']}\\n\"\n",
    "            header += f\"-- Description: {template['description']}\\n\"\n",
    "            header += f\"-- Required Filters: {len(template['filters'])}\\n\"\n",
    "            header += f\"-- Generated: Basic query without WHERE conditions\\n\\n\"\n",
    "            \n",
    "            # 生成基本查询\n",
    "            if is_join and len(tables) > 1:\n",
    "                return self._generate_join_sql(template, query_type, query_id, tables, conditions, relaxation_used)\n",
    "            else:\n",
    "                return self._generate_single_sql(template, query_type, query_id, tables[0], conditions, relaxation_used)\n",
    "        \n",
    "        indices, conditions, relaxation_used = result\n",
    "        \n",
    "        # 确定涉及的表\n",
    "        if \"primary_table\" in template:\n",
    "            tables = [template[\"primary_table\"]]\n",
    "        elif \"tables\" in template:\n",
    "            tables = template[\"tables\"]\n",
    "        else:\n",
    "            tables = [\"player\"]  # 默认表\n",
    "        \n",
    "        # 判断是否生成JOIN查询\n",
    "        is_join_query = query_type.endswith('J') or len(tables) > 1\n",
    "        \n",
    "        if is_join_query and len(tables) > 1:\n",
    "            return self._generate_join_sql(template, query_type, query_id, tables, conditions, relaxation_used)\n",
    "        else:\n",
    "            return self._generate_single_sql(template, query_type, query_id, tables[0], conditions, relaxation_used)\n",
    "    \n",
    "    def _generate_join_sql(self, template, query_type, query_id, tables, conditions, relaxation_used):\n",
    "        \"\"\"生成JOIN SQL\"\"\"\n",
    "        base_type = query_type.rstrip('J')\n",
    "        \n",
    "        # 选择显示列\n",
    "        select_attrs = []\n",
    "        for table in tables[:2]:  # 最多2个表避免SELECT过长\n",
    "            table_attrs = self.table_attr_mapping.get(table, [])[:3]\n",
    "            for attr in table_attrs:\n",
    "                select_attrs.append(f\"{table}.{attr}\")\n",
    "        \n",
    "        select_clause = f\"SELECT {', '.join(select_attrs[:5])}\"\n",
    "        from_clause = f\"FROM {tables[0]}\" + self.generate_join_clause(tables)\n",
    "        where_clause = f\"WHERE {' AND '.join(conditions)}\" if conditions else \"\"\n",
    "        \n",
    "        sql_parts = [select_clause, from_clause]\n",
    "        if where_clause:\n",
    "            sql_parts.append(where_clause)\n",
    "        \n",
    "        # 根据查询类型添加特定子句\n",
    "        if base_type == \"SFWT\":\n",
    "            # TOP-K查询\n",
    "            numeric_attrs = []\n",
    "            for table in tables:\n",
    "                for attr in self.table_attr_mapping.get(table, []):\n",
    "                    if attr in numerical_attr_list:\n",
    "                        numeric_attrs.append(f\"{table}.{attr}\")\n",
    "            \n",
    "            if numeric_attrs:\n",
    "                order_col = random.choice(numeric_attrs)\n",
    "                sql_parts.append(f\"ORDER BY {order_col} {random.choice(['ASC', 'DESC'])}\")\n",
    "                sql_parts.append(f\"LIMIT {random.choice([3, 5, 8, 10])}\")\n",
    "        \n",
    "        elif base_type in [\"SFWG\", \"SFWGA\", \"SFWGAT\"]:\n",
    "            # GROUP BY查询\n",
    "            category_attrs = []\n",
    "            for table in tables:\n",
    "                for attr in self.table_attr_mapping.get(table, []):\n",
    "                    if attr in category_attr_list:\n",
    "                        category_attrs.append(f\"{table}.{attr}\")\n",
    "            \n",
    "            if category_attrs:\n",
    "                group_col = random.choice(category_attrs)\n",
    "                sql_parts.append(f\"GROUP BY {group_col}\")\n",
    "                \n",
    "                if base_type in [\"SFWGA\", \"SFWGAT\"]:\n",
    "                    # 聚合查询\n",
    "                    agg_func = random.choice([\"COUNT\", \"MAX\", \"MIN\", \"AVG\", \"SUM\"])\n",
    "                    numeric_attrs = []\n",
    "                    for table in tables:\n",
    "                        for attr in self.table_attr_mapping.get(table, []):\n",
    "                            if attr in numerical_attr_list:\n",
    "                                numeric_attrs.append(f\"{table}.{attr}\")\n",
    "                    \n",
    "                    if numeric_attrs and agg_func != \"COUNT\":\n",
    "                        agg_col = random.choice(numeric_attrs)\n",
    "                        sql_parts[0] = f\"SELECT {group_col}, {agg_func}({agg_col})\"\n",
    "                    else:\n",
    "                        sql_parts[0] = f\"SELECT {group_col}, COUNT(*)\"\n",
    "                    \n",
    "                    if base_type == \"SFWGAT\":\n",
    "                        sql_parts.append(f\"ORDER BY COUNT(*) DESC\")\n",
    "                        sql_parts.append(f\"LIMIT {random.choice([3, 5, 8])}\")\n",
    "        \n",
    "        elif base_type == \"SFWA\":\n",
    "            # 纯聚合查询\n",
    "            agg_func = random.choice([\"COUNT\", \"MAX\", \"MIN\", \"AVG\", \"SUM\"])\n",
    "            numeric_attrs = []\n",
    "            for table in tables:\n",
    "                for attr in self.table_attr_mapping.get(table, []):\n",
    "                    if attr in numerical_attr_list:\n",
    "                        numeric_attrs.append(f\"{table}.{attr}\")\n",
    "            \n",
    "            if numeric_attrs and agg_func != \"COUNT\":\n",
    "                agg_col = random.choice(numeric_attrs)\n",
    "                sql_parts[0] = f\"SELECT {agg_func}({agg_col})\"\n",
    "            else:\n",
    "                sql_parts[0] = f\"SELECT COUNT(*)\"\n",
    "        \n",
    "        # 生成完整SQL\n",
    "        query_sql = \"\\n\".join(sql_parts) + \";\"\n",
    "        schema_sql = self.create_multi_table_schema(tables)\n",
    "        \n",
    "        header = f\"-- Query {query_id} - {query_type} (JOIN Query)\\n\"\n",
    "        header += f\"-- Template: {template['name']}\\n\"\n",
    "        header += f\"-- Description: {template['description']}\\n\"\n",
    "        header += f\"-- Tables: {', '.join(tables)}\\n\"\n",
    "        if conditions:\n",
    "            header += f\"-- Filters: {len(conditions)}/{len(template['filters'])} (using {len(conditions)} filters)\"\n",
    "            if relaxation_used != \"FAILED\" and relaxation_used > 0:\n",
    "                header += f\" (relaxed {relaxation_used} levels)\"\n",
    "        else:\n",
    "            header += f\"-- Filters: 0/{len(template['filters'])} (no WHERE conditions)\"\n",
    "        header += \"\\n\\n\"\n",
    "        \n",
    "        return header + schema_sql + \"\\n\\n\" + query_sql + \"\\n\\n\" + \"-\" * 60 + \"\\n\\n\"\n",
    "    \n",
    "    def _generate_single_sql(self, template, query_type, query_id, table_name, conditions, relaxation_used):\n",
    "        \"\"\"生成单表SQL\"\"\"\n",
    "        table_attrs = self.table_attr_mapping.get(table_name, [])\n",
    "        select_attrs = random.sample(table_attrs, min(4, len(table_attrs)))\n",
    "        \n",
    "        select_clause = f\"SELECT {', '.join(select_attrs)}\"\n",
    "        from_clause = f\"FROM {table_name}\"\n",
    "        where_clause = f\"WHERE {' AND '.join(conditions)}\" if conditions else \"\"\n",
    "        \n",
    "        sql_parts = [select_clause, from_clause]\n",
    "        if where_clause:\n",
    "            sql_parts.append(where_clause)\n",
    "        \n",
    "        # 根据查询类型添加子句\n",
    "        if query_type == \"SFWT\":\n",
    "            numeric_attrs = [attr for attr in table_attrs if attr in numerical_attr_list]\n",
    "            if numeric_attrs:\n",
    "                order_col = random.choice(numeric_attrs)\n",
    "                sql_parts.append(f\"ORDER BY {order_col} {random.choice(['ASC', 'DESC'])}\")\n",
    "                sql_parts.append(f\"LIMIT {random.choice([3, 5, 8, 10])}\")\n",
    "        \n",
    "        elif query_type in [\"SFWG\", \"SFWGA\", \"SFWGAT\"]:\n",
    "            category_attrs = [attr for attr in table_attrs if attr in category_attr_list]\n",
    "            if category_attrs:\n",
    "                group_col = random.choice(category_attrs)\n",
    "                sql_parts.append(f\"GROUP BY {group_col}\")\n",
    "                \n",
    "                if query_type in [\"SFWGA\", \"SFWGAT\"]:\n",
    "                    agg_func = random.choice([\"COUNT\", \"MAX\", \"MIN\", \"AVG\", \"SUM\"])\n",
    "                    numeric_attrs = [attr for attr in table_attrs if attr in numerical_attr_list]\n",
    "                    \n",
    "                    if numeric_attrs and agg_func != \"COUNT\":\n",
    "                        agg_col = random.choice(numeric_attrs)\n",
    "                        sql_parts[0] = f\"SELECT {group_col}, {agg_func}({agg_col})\"\n",
    "                    else:\n",
    "                        sql_parts[0] = f\"SELECT {group_col}, COUNT(*)\"\n",
    "                    \n",
    "                    if query_type == \"SFWGAT\":\n",
    "                        sql_parts.append(f\"ORDER BY COUNT(*) DESC\")\n",
    "                        sql_parts.append(f\"LIMIT {random.choice([3, 5, 8])}\")\n",
    "        \n",
    "        elif query_type == \"SFWA\":\n",
    "            agg_func = random.choice([\"COUNT\", \"MAX\", \"MIN\", \"AVG\", \"SUM\"])\n",
    "            numeric_attrs = [attr for attr in table_attrs if attr in numerical_attr_list]\n",
    "            \n",
    "            if numeric_attrs and agg_func != \"COUNT\":\n",
    "                agg_col = random.choice(numeric_attrs)\n",
    "                sql_parts[0] = f\"SELECT {agg_func}({agg_col})\"\n",
    "            else:\n",
    "                sql_parts[0] = f\"SELECT COUNT(*)\"\n",
    "        \n",
    "        # 生成Schema\n",
    "        schema_parts = []\n",
    "        for attr in table_attrs:\n",
    "            if attr in numerical_attr_list:\n",
    "                schema_parts.append(f\"    {attr} FLOAT\")\n",
    "            else:\n",
    "                schema_parts.append(f\"    {attr} VARCHAR(255)\")\n",
    "        \n",
    "        schema_sql = f\"CREATE TABLE {table_name} (\\n\" + \",\\n\".join(schema_parts) + \"\\n);\"\n",
    "        query_sql = \"\\n\".join(sql_parts) + \";\"\n",
    "        \n",
    "        header = f\"-- Query {query_id} - {query_type} (Single Table)\\n\"\n",
    "        header += f\"-- Template: {template['name']}\\n\"\n",
    "        header += f\"-- Description: {template['description']}\\n\"\n",
    "        header += f\"-- Table: {table_name}\\n\"\n",
    "        if conditions:\n",
    "            header += f\"-- Filters: {len(conditions)}/{len(template['filters'])} (using {len(conditions)} filters)\"\n",
    "            if relaxation_used != \"FAILED\" and relaxation_used > 0:\n",
    "                header += f\" (relaxed {relaxation_used} levels)\"\n",
    "        else:\n",
    "            header += f\"-- Filters: 0/{len(template['filters'])} (no WHERE conditions)\"\n",
    "        header += \"\\n\\n\"\n",
    "        \n",
    "        return header + schema_sql + \"\\n\\n\" + query_sql + \"\\n\\n\" + \"-\" * 60 + \"\\n\\n\"\n",
    "\n",
    "def generate_nba_template_queries():\n",
    "    \"\"\"生成NBA模板查询\"\"\"\n",
    "    \n",
    "    # 创建输出目录\n",
    "    base_dir = \"./NBA_Template_Queries/\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # 创建生成器\n",
    "    generator = NBASQLTemplateGenerator(dataframes, attr_value_dict, filter_dict, join_relationships)\n",
    "    \n",
    "    queries_per_type = 3  # 每个类型生成3个查询，提高成功率\n",
    "    total_generated = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    # 为每个模板生成查询\n",
    "    for template in NBA_TEMPLATES:\n",
    "        template_dir = os.path.join(base_dir, template[\"name\"])\n",
    "        os.makedirs(template_dir, exist_ok=True)\n",
    "        \n",
    "        # 确定查询类型\n",
    "        is_multi_table = len(template.get(\"tables\", [])) > 1\n",
    "        query_types = NBA_SINGLE_TYPES + (NBA_JOIN_TYPES if is_multi_table else [])\n",
    "        \n",
    "        template_stats = {}\n",
    "        \n",
    "        for qtype in query_types:\n",
    "            sql_content = []\n",
    "            query_id = 1\n",
    "            generated = 0\n",
    "            attempts = 0\n",
    "            \n",
    "            while generated < queries_per_type and attempts < queries_per_type * 2:  # 减少尝试次数\n",
    "                attempts += 1\n",
    "                sql = generator.generate_query_sql(template, qtype, query_id)\n",
    "                \n",
    "                if sql:\n",
    "                    sql_content.append(sql)\n",
    "                    # 现在总是算作生成成功，不管是否有FAILED标记\n",
    "                    generated += 1\n",
    "                    total_generated += 1\n",
    "                    query_id += 1\n",
    "            \n",
    "            template_stats[qtype] = generated\n",
    "            \n",
    "            # 保存文件\n",
    "            filename = os.path.join(template_dir, f\"{qtype}.sql\")\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"-- NBA {template['description']} - {qtype} 查询\\n\")\n",
    "                f.write(f\"-- 模板: {template['name']}\\n\")\n",
    "                f.write(f\"-- Filter数量: {len(template['filters'])}\\n\")\n",
    "                f.write(f\"-- 涉及表: {template.get('tables', [template.get('primary_table', 'auto')])}\\n\")\n",
    "                f.write(\"-- \" + \"=\" * 60 + \"\\n\\n\")\n",
    "                f.write(\"\".join(sql_content))\n",
    "    \n",
    "    # 生成汇总\n",
    "    summary = f\"\"\"NBA模板查询生成汇总\n",
    "{\"=\"*50}\n",
    "\n",
    "总模板数: {len(NBA_TEMPLATES)}\n",
    "成功生成: {total_generated} 个查询\n",
    "生成失败: {total_failed} 个查询\n",
    "成功率: {total_generated/(total_generated+total_failed)*100:.1f}% (如果有查询的话)\n",
    "\n",
    "模板类型分布:\n",
    "- 单表模板: {len([t for t in NBA_TEMPLATES if 'primary_table' in t])} 个\n",
    "- 多表模板: {len([t for t in NBA_TEMPLATES if 'tables' in t])} 个\n",
    "\n",
    "查询类型: \n",
    "- 单表查询类型: {len(NBA_SINGLE_TYPES)} 种\n",
    "- JOIN查询类型: {len(NBA_JOIN_TYPES)} 种\n",
    "\n",
    "输出目录: {base_dir}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(os.path.join(base_dir, \"SUMMARY.txt\"), 'w', encoding='utf-8') as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    return total_generated\n",
    "\n",
    "# 执行生成\n",
    "try:\n",
    "    total_queries = generate_nba_template_queries()\n",
    "    print(f\"✅ NBA模板查询生成完成: {total_queries} 个查询\")\n",
    "    print(f\"📁 文件保存在: ./NBA_Template_Queries/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 生成错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
