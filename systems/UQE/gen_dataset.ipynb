{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf97b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dataset = \"institutes\"\n",
    "limit = 10\n",
    "\n",
    "data_root_dir = \"datasets_origin/\"\n",
    "data_target_root_dir = \"datasets/\"\n",
    "\n",
    "data_dir = os.path.join(data_root_dir, dataset)\n",
    "data_target_dir = os.path.join(data_target_root_dir, dataset)\n",
    "\n",
    "os.makedirs(data_target_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50be827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12.txt', '37.txt', '51.txt', '61.txt', '74.txt', '83.txt', '94.txt', '103.txt', '106.txt', '109.txt', '110.txt', '116.txt', '132.txt', '134.txt', '135.txt', '156.txt', '165.txt', '195.txt', '214.txt', '216.txt', '217.txt', '221.txt', '225.txt', '226.txt', '230.txt', '232.txt', '243.txt', '251.txt', '263.txt', '273.txt', '277.txt', '278.txt', '288.txt', '291.txt', '298.txt', '306.txt', '307.txt', '315.txt', '316.txt', '326.txt', '339.txt', '344.txt', '353.txt', '356.txt', '362.txt', '363.txt', '364.txt', '380.txt', '381.txt', '385.txt', '392.txt', '393.txt', '401.txt', '417.txt', '419.txt', '453.txt', '467.txt', '476.txt', '487.txt', '489.txt', '490.txt', '491.txt', '492.txt', '493.txt', '509.txt', '515.txt', '519.txt', '521.txt', '544.txt', '564.txt', '566.txt', '583.txt', '585.txt', '670.txt', '678.txt', '712.txt', '953.txt', '959.txt', '1110.txt', '1129.txt', '1206.txt', '1361.txt', '1415.txt', '1416.txt', '1534.txt', '1567.txt', '1635.txt', '1709.txt', '1755.txt', '1768.txt', '1769.txt', '1796.txt', '1821.txt', '1890.txt', '1909.txt', '1924.txt', '1953.txt', '1954.txt', '1962.txt', '1965.txt']\n"
     ]
    }
   ],
   "source": [
    "def create_json():\n",
    "    files = os.listdir(data_dir)\n",
    "    files = [file for file in files if file != '.DS_Store']\n",
    "    files = sorted(files, key=lambda x: int(x.split('.')[0]) if x.endswith('.txt') else 0)\n",
    "    files = files[:limit]\n",
    "    print(files)\n",
    "    data = []\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "            \n",
    "            data.append({\n",
    "                \"id\": file[:-4],\n",
    "                \"description\": content\n",
    "            })\n",
    "\n",
    "    json_file_path = os.path.join(data_target_dir, \"dataset.json\")\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "create_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uqe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
